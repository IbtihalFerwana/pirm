"""

## Section 4.2: Evaluating Subpopulation Shifts
Run the python script `dataset/subpopulation_shift_cat_dog_indoor_outdoor.py` to reproduce the MetaShift subpopulation shift dataset (based on Visual Genome images) in paper Appendix D. 
```sh
cd dataset/
python subpopulation_shift_cat_dog_indoor_outdoor.py
```
The python script generates a “Cat vs. Dog” dataset, where the general contexts “indoor/outdoor” have a natural spurious correlation with the class labels. 


The following files will be generated by executing the python script `dataset/subpopulation_shift_cat_dog_indoor_outdoor.py`. 

### Output files (mixed version: for reproducing experiments)

```plain
/data/MetaShift/MetaShift-subpopulation-shift
├── imageID_to_group.pkl
├── train/
    ├── cat/             (more cat(indoor) images than cat(outdoor))
    ├── dog/             (more dog(outdoor) images than dog(indoor)) 
├── val_out_of_domain/
    ├── cat/             (cat(indoor):cat(outdoor)=1:1)
    ├── dog/             (dog(indoor):dog(outdoor)=1:1) 
```
where `imageID_to_group.pkl` is a dictionary with 4 keys : 
`'cat(outdoor)'`, `'cat(outdoor)'`, `'dog(outdoor)'`, `'dog(outdoor)'`. 
The corresponding value of each key is the list of the names of the images that belongs to that subset. 
You can tune the `NUM_MINORITY_IMG` to control the amount of subpopulation shift.  

### Output files (unmixed version, for other potential uses)
To facilitate other potential uses, we also outputs an unmixed version, where we output the `'cat(outdoor)'`, `'cat(outdoor)'`, `'dog(outdoor)'`, `'dog(outdoor)'` into 4 seperate folders. 
```plain
/data/MetaShift/MetaShift-Cat-Dog-indoor-outdoor
├── imageID_to_group.pkl
├── train/
    ├── cat/             (all cat(indoor) images)
    ├── dog/             (all dog(outdoor) images) 
├── val_out_of_domain/
    ├── cat/             (all cat(outdoor) images)
    ├── dog/             (all dog(indoor) images) 
```

"""
CUSTOM_SPLIT_DATASET_FOLDER = 'data/MetaShift/MetaShift-Cat-Dog-indoor-outdoor'


import pandas as pd 
import seaborn as sns

import pickle
import numpy as np
import json, re, math
from collections import Counter, defaultdict
from itertools import repeat
import pprint
import os, errno
from PIL import Image
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import shutil # for copy files
import networkx as nx # graph vis
import pandas as pd
from sklearn.decomposition import TruncatedSVD
import networkx.algorithms.community as nx_comm
import itertools
import random
import argparse
import Constants
import networkx as nx
from sklearn.model_selection import train_test_split
#IMAGE_DATA_FOLDER          = Constants.IMAGE_DATA_FOLDER # from Metashift code
IMAGE_DATA_FOLDER = ''
from generate_full_MetaShift import preprocess_groups, build_subset_graph, copy_image_for_subject
from generate_full_MetaShift_exp1 import build_subset_graph as sG
import random

def shuffle_and_truncate(img_id_set, truncate=500):
    img_id_list = sorted(img_id_set)
    random.Random(42).shuffle(img_id_list)
    return img_id_list[:truncate]

def print_communities(subject_data, node_name_to_img_id, trainsg_dupes, subject_str):
    ##################################
    # Community detection 
    ##################################
    G = build_subset_graph(subject_data, node_name_to_img_id, trainsg_dupes, subject_str)

    import networkx.algorithms.community as nxcom

    # Find the communities
    communities = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)
    # Count the communities
    print("The graph has {} communities.".format(len(communities)) )
    for community in communities:
        community_merged = set()
        for node_str in community:
            node_str = node_str.replace('\n', '')
            node_image_IDs = node_name_to_img_id[node_str]
            community_merged.update(node_image_IDs)
            # print(node_str , len(node_image_IDs), end=';')

        print('total size:',len(community_merged))
        community_set = set([ x.replace('\n', '') for x in community])
        print(community_set, '\n\n')
    return G 


def parse_dataset_scheme_preexisting_data(dataset_scheme, node_name_to_img_id,dataset_folder=None, exclude_img_id=set(),include_img_id=set(), additional_comms = set(), max_additional_size = 0,split='test', copy=True, trunc_size=2500):
    """
    exclude_img_id contains both trainsg_dupes and test images that we do not want to leak 
    """
    community_name_to_img_id = defaultdict(set)
    print(" START *** exlude image length: ", len(exclude_img_id))
    all_img_id = set()
    exclude_img_id_local = set()
    exclude_img_id_local = exclude_img_id.copy()
    # print("***** split ****", split)
    ##################################
    # Iterate subject_str: e.g., cat
    ##################################
    for subject_str in dataset_scheme:        
        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        for community_name in dataset_scheme[subject_str]:
            ##################################
            # Iterate node_name: e.g., 'cat(cup)', 'cat(sofa)', 'cat(chair)'
            ##################################
            print("community name: ", community_name)
            for node_name in dataset_scheme[subject_str][community_name]:
                # print("node name: ", node_name)
                community_name_to_img_id[community_name].update(node_name_to_img_id[node_name] - exclude_img_id_local)
            print("community_name_to_img_id first : ", len(community_name_to_img_id[community_name]))
            community_name_to_img_id[community_name] = community_name_to_img_id[community_name].intersection(include_img_id)
            print("community_name_to_img_id after intersection: ", len(community_name_to_img_id[community_name]))
            community_name_to_img_id[community_name] = set(shuffle_and_truncate(community_name_to_img_id[community_name], trunc_size))
            print("community_name_to_img_id after truncation: ", len(community_name_to_img_id[community_name]))

            exclude_img_id_local.update(community_name_to_img_id[community_name])
            all_img_id.update(community_name_to_img_id[community_name])
        if max_additional_size > 0:
            for community_name in dataset_scheme[subject_str]:
                max_additional_size = int(max_additional_size)
                print("max_additional_size: ", max_additional_size)
                additional_size = int(max_additional_size)
                additional_imgs = set()
                print(" **** additional training data *** ")
                for node_name in additional_comms[subject_str]:
                    print("node name: ", node_name)
                    additional_imgs.update(node_name_to_img_id[node_name] - exclude_img_id_local)
                    print("additional image size: ", len(additional_imgs))
                    additional_imgs = additional_imgs.intersection(include_img_id)
                    print("additional image size after intersection with irm: ", len(additional_imgs))
                    additional_imgs = set(shuffle_and_truncate(additional_imgs, additional_size))
                    all_img_id.update(additional_imgs)
                    exclude_img_id_local.update(additional_imgs)
                    print("additional image size after truncation: ", len(additional_imgs))
                    if len(additional_imgs) < max_additional_size:
                        additional_size = max_additional_size - len(additional_imgs) 
                if len(additional_imgs) < max_additional_size:
                    ## take more data to fill in
                    ## remaining to add: 
                    rm_size = max_additional_size - len(additional_imgs) 
                    rm_imgs = include_img_id-all_img_id
                    community_name_to_img_id[community_name].update(set(shuffle_and_truncate(rm_imgs, rm_size)))
                    exclude_img_id_local.update(community_name_to_img_id[community_name])
                    all_img_id.update(community_name_to_img_id[community_name])

                community_name_to_img_id[community_name].update(additional_imgs)
                print("community_name_to_img_id after additions: ", len(community_name_to_img_id[community_name]))

        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        if copy:
            root_folder = os.path.join(dataset_folder, split)
            copy_image_for_subject(root_folder, subject_str, dataset_scheme[subject_str], community_name_to_img_id, trainsg_dupes=set(), use_symlink=False) # use False to share 

    return community_name_to_img_id, all_img_id
def parse_dataset_scheme(dataset_scheme, node_name_to_img_id, exclude_img_id=set(), copy=True, split='test'):
    """
    exclude_img_id contains both trainsg_dupes and test images that we do not want to leak 
    """
    community_name_to_img_id = defaultdict(set)
    all_img_id = set()

    ##################################
    # Iterate subject_str: e.g., cat
    ##################################
    for subject_str in dataset_scheme:        
        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        for community_name in dataset_scheme[subject_str]:
            ##################################
            # Iterate node_name: e.g., 'cat(cup)', 'cat(sofa)', 'cat(chair)'
            ##################################
            for node_name in dataset_scheme[subject_str][community_name]:
                community_name_to_img_id[community_name].update(node_name_to_img_id[node_name] - exclude_img_id)
                all_img_id.update(node_name_to_img_id[node_name] - exclude_img_id)
            print(community_name, 'Size:', len(community_name_to_img_id[community_name]) )


        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        if copy:
            root_folder = os.path.join(CUSTOM_SPLIT_DATASET_FOLDER, split)
            copy_image_for_subject(root_folder, subject_str, dataset_scheme[subject_str], community_name_to_img_id, trainsg_dupes=set(), use_symlink=False) # use False to share 

    return community_name_to_img_id, all_img_id


def get_all_nodes_in_dataset(dataset_scheme):
    all_nodes = set()
    ##################################
    # Iterate subject_str: e.g., cat
    ##################################
    for subject_str in dataset_scheme:        
        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        for community_name in dataset_scheme[subject_str]:
            ##################################
            # Iterate node_name: e.g., 'cat(cup)', 'cat(sofa)', 'cat(chair)'
            ##################################
            for node_name in dataset_scheme[subject_str][community_name]:
                all_nodes.add(node_name)
    return all_nodes

def generate_splitted_metadaset(args):

    root_folder = args.data_folder
    if os.path.isdir(root_folder): 
        shutil.rmtree(root_folder) 
    os.makedirs(root_folder, exist_ok = False)

    global IMAGE_DATA_FOLDER 
    IMAGE_DATA_FOLDER = args.images_folder


    node_name_to_img_id, most_common_list, subjects_to_all_set, subject_group_summary_dict = preprocess_groups(IMAGE_DATA_FOLDER,output_files_flag=False)

    ##################################
    # Removing ambiguous images that have both cats and dogs 
    ##################################
    trainsg_dupes = node_name_to_img_id['cat(dog)'] # can also use 'dog(cat)'
    trainsg_dupes.union(node_name_to_img_id['dog(cat)'])
    subject_str_to_Graphs = dict()


    for subject_str in ['cat', 'dog']:
        subject_data = [ x for x in subject_group_summary_dict[subject_str].keys() if x not in ['cat(dog)', 'dog(cat)'] ]
        # print('subject_data', subject_data)
        ##################################
        # Print detected communities in Meta-Graph
        ##################################
        G = print_communities(subject_data, node_name_to_img_id, trainsg_dupes, subject_str) # print detected communities, which guides us the train/test split. 
        subject_str_to_Graphs[subject_str] = G




    test_set_scheme = {
        'cat': {
            'cat(outdoor)': {
                'cat(car)',
                'cat(fence)', 'cat(grass)', 'cat(roof)', 'cat(bench)', 'cat(bird)', 'cat(house)', 
            },
        },
        'dog': {
            'dog(indoor)': {
                'dog(screen)', 'dog(shelf)', 'dog(desk)', 'dog(picture)', 'dog(laptop)',
                'dog(remote control)', 'dog(blanket)', 'dog(bed)', 'dog(sheet)', 'dog(lamp)', 'dog(books)', 'dog(pillow)', 'dog(curtain)', 
                'dog(container)', 'dog(table)', 'dog(cup)', 'dog(plate)', 'dog(food)', 'dog(box)',
                'dog(rug)', 'dog(floor)', 'dog(cabinet)', 'dog(towel)',
                'dog(bowl)',
                'dog(television)', 'dog(carpet)',
                'dog(sofa)',

            },    
        },    
    }

    train_set_scheme = {
        'cat': {
            'cat(indoor)': {
                'cat(speaker)', 'cat(computer)', 'cat(screen)', 'cat(laptop)', 'cat(computer mouse)', 'cat(keyboard)', 'cat(monitor)', 'cat(desk)',
                'cat(sheet)', 'cat(bed)', 'cat(blanket)', 'cat(remote control)', 'cat(comforter)', 'cat(pillow)', 'cat(couch)',
                'cat(books)', 'cat(book)', 'cat(television)', 'cat(bookshelf)', 'cat(blinds)',
                'cat(sink)', 'cat(bottle)', 'cat(faucet)', 'cat(towel)', 'cat(counter)',
                'cat(curtain)', 'cat(toilet)', 'cat(pot)', 
                'cat(carpet)', 'cat(toy)', 'cat(floor)',
                'cat(plate)', 'cat(rug)', 'cat(food)', 'cat(table)',
                'cat(box)', 'cat(paper)', 'cat(suitcase)', 'cat(bag)',
                'cat(container)', 'cat(vase)', 'cat(shelf)', 'cat(bowl)',
                'cat(picture)', 'cat(papers)', 'cat(lamp)',
                'cat(cup)', 'cat(sofa)', 
            },
        },
        'dog': {
            'dog(outdoor)': {
                'dog(house)', 'dog(grass)', 'dog(horse)', 'dog(fence)', 'dog(cow)', 'dog(sheep)', 'dog(dirt)',
                'dog(car)', 'dog(motorcycle)', 'dog(truck)', 'dog(helmet)', 
                'dog(snow)',
                'dog(flag)', 'dog(boat)', 'dog(rope)', 'dog(trees)', 'dog(frisbee)',
                'dog(bike)', 'dog(bicycle)', 
                'dog(sand)', 'dog(surfboard)', 'dog(water)', 
                'dog(fire hydrant)', 'dog(pole)', 
                'dog(skateboard)',
                'dog(bench)', 'dog(trash can)',
            },
        },
        
    }
    additional_test_set_scheme = dict() # empty dict 

    print('========== test set info ==========')
    test_community_name_to_img_id, test_all_img_id = parse_dataset_scheme(test_set_scheme, node_name_to_img_id, exclude_img_id=trainsg_dupes, split='test', copy=False)
    # print('test_all_img_id', len(test_all_img_id))
    print('========== train set info ==========')
    train_community_name_to_img_id, train_all_img_id = parse_dataset_scheme(train_set_scheme, node_name_to_img_id, exclude_img_id=test_all_img_id.union(trainsg_dupes), split='train',copy=False)
    # print('========== additional test set info ==========')
    # additional_test_community_name_to_img_id, additional_test_all_img_id = parse_dataset_scheme(additional_test_set_scheme, node_name_to_img_id, exclude_img_id=train_all_img_id.union(trainsg_dupes), split='test')

    """
    ** Simulating subpopulation shifts ** 

    Functionality: re-export dataset for domain generalization algorithms. 
    parameter 1: ratio: hardness of subpopulation shift 
    parameter 2: name of the output dir 

    the structure of the dataset dir should look as this: 
        train/
            cat/
                ...images
            dog/
                ...images
        test/
            cat/
                ...images
            dog/
                ...images
        imageID_to_group.pkl -- specifying group information. 
    """

    # if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER): 
    #     shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER) 
    # os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER, exist_ok = False)

    

    cat_outdoor_images = set(shuffle_and_truncate(test_community_name_to_img_id['cat(outdoor)'], 294)) # 150 for test, 0-150 for training
    dog_indoor_images = set(shuffle_and_truncate(test_community_name_to_img_id['dog(indoor)']-cat_outdoor_images, 294))
    cat_indoor_images = set(shuffle_and_truncate(train_community_name_to_img_id['cat(indoor)']-dog_indoor_images, 994)) # 150 for test, 450 for training, 
    dog_outdoor_images = set(shuffle_and_truncate(train_community_name_to_img_id['dog(outdoor)']-cat_indoor_images, 994))

    # cat_outdoor_images = list(cat_outdoor_images)
    # dog_indoor_images = list(dog_indoor_images)
    # cat_indoor_images = list(cat_indoor_images)
    # dog_outdoor_images = list(dog_outdoor_images)

    from sklearn.model_selection import train_test_split
    # cat_outdoor_train, cat_outdoor_test, dog_indoor_train, dog_indoor_test = train_test_split(cat_outdoor_images, dog_indoor_images, test_size=144, random_state=42)
    # cat_indoor_train, cat_indoor_test, dog_outdoor_train, dog_outdoor_test = train_test_split(cat_indoor_images, dog_outdoor_images, test_size=144, random_state=42)

    cat_indoor_test = set(shuffle_and_truncate(cat_indoor_images, 144))
    cat_outdoor_test = set(shuffle_and_truncate(cat_outdoor_images-cat_indoor_test, 144))
    dog_indoor_test = set(shuffle_and_truncate(dog_indoor_images, 144))
    dog_outdoor_test = set(shuffle_and_truncate(dog_outdoor_images-dog_indoor_test, 144))

    all_test_imgs = cat_outdoor_test.union(cat_indoor_test).union(dog_outdoor_test).union(dog_indoor_test)
    exclude_imgs = all_test_imgs
    
    p = args.mp
    total_size = 1700
    env_size = total_size/2
    min_size = int(p*total_size/2)
    maj_size = int((1-p)*total_size/2)
    add_p = args.add_p
    print("percentages: ",min_size, maj_size)
    print("===== new sizse =====")
    
    cat_outdoor_train = set(shuffle_and_truncate(cat_outdoor_images-exclude_imgs, min_size))
    exclude_imgs.update(cat_outdoor_train)
    
    cat_indoor_train = set(shuffle_and_truncate(cat_indoor_images-exclude_imgs, maj_size))
    exclude_imgs.update(cat_indoor_train)  

    dog_indoor_train = set(shuffle_and_truncate(dog_indoor_images-exclude_imgs, min_size))
    exclude_imgs.update(dog_indoor_train)

    dog_outdoor_train = set(shuffle_and_truncate(dog_outdoor_images-exclude_imgs, maj_size))
    
    all_train_imgs = cat_outdoor_train.union(cat_indoor_train).union(dog_outdoor_train).union(dog_indoor_train)

    # sizes
    print("cat_outdoor_train: ",len(cat_outdoor_train)) # minority
    print("cat_indoor_train: ",len(cat_indoor_train))
    print("dog_outdoor_train: ",len(dog_outdoor_train))
    print("dog_indoor_train: ",len(dog_indoor_train)) # minority
    

    print("total train images : ",len(all_train_imgs))
    print("total test images size: ",len(all_test_imgs))
    
    print(" ======== Dog Communities Graph ===========")
    
    # get nodes keys for dog graph
    community_name_to_img_id = defaultdict(set)
    for node_name in train_set_scheme['dog']['dog(outdoor)']:
        # print("node name: ", node_name)
        community_name_to_img_id[node_name] = node_name_to_img_id[node_name].intersection(all_train_imgs)
    for node_name in test_set_scheme['dog']['dog(indoor)']:
        # print("node name: ", node_name)
        community_name_to_img_id[node_name] = node_name_to_img_id[node_name].intersection(all_train_imgs)

    community_name_to_img_id['outdoor_test'] = dog_outdoor_test
    community_name_to_img_id['indoor_test'] = dog_indoor_test
    dog_community_name_to_img_id = community_name_to_img_id

    # print(community_name_to_img_id.keys())            
    N_sets = len(community_name_to_img_id.keys())
    Adjacency_matrix = np.ones((N_sets, N_sets))
    for i, ii in enumerate(community_name_to_img_id.keys()):
        for j,jj in enumerate(community_name_to_img_id.keys()):
            set_A = set(community_name_to_img_id[ii]) - trainsg_dupes
            set_B = set(community_name_to_img_id[jj]) - trainsg_dupes
            overlap_set = set_A.intersection(set_B)
  
            if len(overlap_set) == 0:
                edge_weight = 0
            else: 
                edge_weight = len(overlap_set) / min( len(set_A), len(set_B) )
            Adjacency_matrix[i,j] = Adjacency_matrix[j,i] = edge_weight
            
    labels = []
    for i, x in enumerate(community_name_to_img_id.keys()):
        labels.append(x.replace('(', '\n('))
    A_pd = pd.DataFrame(np.matrix(Adjacency_matrix), index=labels, columns=labels)
    G_dog_all = nx.from_pandas_adjacency(A_pd)

    np.random.seed(42)
    spectral_pos = nx.spectral_layout(
        G=G_dog_all, 
        dim=5,
        # dim = (3,2)
        )
    dists = []
    subs = []
    for sub in train_set_scheme['dog']['dog(outdoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['outdoor_test'])  
    
    for sub in test_set_scheme['dog']['dog(indoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['outdoor_test'])  
        dists.append(dist)  
            
    subs = np.array(subs)
    dog_outdoor_dists = subs[np.argsort(dists)]

    
    dists = []
    subs = []
    for sub in test_set_scheme['dog']['dog(indoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['indoor_test'])  
        dists.append(dist)   

    for sub in train_set_scheme['dog']['dog(outdoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['indoor_test'])  
        dists.append(dist)   
            
    subs = np.array(subs)
    dog_indoor_dists = subs[np.argsort(dists)]
    
    print(" ======== Cat Communities Graph ===========")

    community_name_to_img_id = defaultdict(set)
    for node_name in test_set_scheme['cat']['cat(outdoor)']:
        # print("node name: ", node_name)
        community_name_to_img_id[node_name] = node_name_to_img_id[node_name].intersection(all_train_imgs)
    for node_name in train_set_scheme['cat']['cat(indoor)']:
        # print("node name: ", node_name)
        community_name_to_img_id[node_name] = node_name_to_img_id[node_name].intersection(all_train_imgs)

    community_name_to_img_id['outdoor_test'] = cat_outdoor_test
    community_name_to_img_id['indoor_test'] = cat_indoor_test
    cat_community_name_to_img_id = community_name_to_img_id

    # print(community_name_to_img_id.keys())            
    N_sets = len(community_name_to_img_id.keys())
    Adjacency_matrix = np.ones((N_sets, N_sets))
    for i, ii in enumerate(community_name_to_img_id.keys()):
        for j,jj in enumerate(community_name_to_img_id.keys()):
            set_A = set(community_name_to_img_id[ii]) - trainsg_dupes
            set_B = set(community_name_to_img_id[jj]) - trainsg_dupes
            overlap_set = set_A.intersection(set_B)
  
            if len(overlap_set) == 0:
                edge_weight = 0
            else: 
                edge_weight = len(overlap_set) / min( len(set_A), len(set_B) )
            Adjacency_matrix[i,j] = Adjacency_matrix[j,i] = edge_weight
            
    labels = []
    for i, x in enumerate(community_name_to_img_id.keys()):
        labels.append(x.replace('(', '\n('))
    A_pd = pd.DataFrame(np.matrix(Adjacency_matrix), index=labels, columns=labels)
    G_dog_all = nx.from_pandas_adjacency(A_pd)
    # print("Nodes: ", G_dog_all.nodes())

    spectral_pos = nx.spectral_layout(
        G=G_dog_all, 
        dim=5,
        )
    
    dists = []
    subs = []
    for sub in test_set_scheme['cat']['cat(outdoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['outdoor_test'])  
        dists.append(dist)   
    
    for sub in train_set_scheme['cat']['cat(indoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['outdoor_test'])  
        dists.append(dist)   
            
    subs = np.array(subs)
    cat_outdoor_dists = subs[np.argsort(dists)]

    dists = []
    subs = []
    for sub in train_set_scheme['cat']['cat(indoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['indoor_test'])  
        dists.append(dist)   

    for sub in test_set_scheme['cat']['cat(outdoor)']:
        subs.append(sub)
        dist = np.linalg.norm(spectral_pos[sub.replace('(','\n(')] - spectral_pos['indoor_test'])  
        dists.append(dist)   

            
    subs = np.array(subs)
    cat_indoor_dists = subs[np.argsort(dists)]

    print("======= Partitioning - Dog  ========")

    # dog outdoor
    total_pirm_size = int(total_size/2) # 850
    partition_size = int(total_pirm_size/2) # 450
    max_sub_partition_size = int(partition_size/2) # 212
    max_additional_size = int(max_sub_partition_size*add_p)
    print("max_sub_partition_size: ",max_sub_partition_size)
    
    def sample_partitions(indists, outdits, max_sub_partition_size, max_additional_size, add_p, node_name_to_img_id, include_imgs, exclude_imgs):
        env_p =set()
        additional_samples = set()
        exclude_img_id_local = set()
        exclude_img_id_local = exclude_imgs.copy()
        for node_name in indists:
            if len(env_p) < max_sub_partition_size:
                env_p.update(node_name_to_img_id[node_name].intersection(include_imgs)-exclude_img_id_local)
            elif len(env_p) >= max_sub_partition_size:
                if add_p > 0:
                    if len(additional_samples) < max_additional_size:
                        additional_samples.update(node_name_to_img_id[node_name].intersection(include_imgs)-env_p)
        if add_p > 0:
            if len(additional_samples) < max_additional_size:
                for node_name in outdits:
                    if len(additional_samples) < max_additional_size:
                        additional_samples.update(node_name_to_img_id[node_name].intersection(include_imgs)-env_p)

        additional_samples = set(shuffle_and_truncate(additional_samples,max_additional_size))
        env_p = set(shuffle_and_truncate(env_p,max_sub_partition_size))
        exclude_img_id_local.update(env_p)
        env_p.update(additional_samples)
        return env_p, exclude_img_id_local
    exclude_imgs = set()
    dog_outdoor_p0_train, exclude_imgs = sample_partitions(
                                            dog_outdoor_dists,
                                            dog_indoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs, 
                                            exclude_imgs)
    dog_outdoor_p1_train, exclude_imgs = sample_partitions(
                                            dog_outdoor_dists,
                                            dog_indoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    dog_indoor_p0_train, exclude_imgs = sample_partitions(
                                            dog_indoor_dists,
                                            dog_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    dog_indoor_p1_train, exclude_imgs = sample_partitions(
                                            dog_indoor_dists,
                                            dog_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    print("dog_outdoor_p1_train: ", len(dog_outdoor_p0_train))
    print("dog_outdoor_p2_train: ", len(dog_outdoor_p1_train))
    print("dog_indoor_p1_train: ", len(dog_indoor_p0_train))
    print("dog_indoor_p2_train: ", len(dog_indoor_p1_train))
    
    
    cat_outdoor_p0_train, exclude_imgs = sample_partitions(
                                            cat_outdoor_dists,
                                            cat_indoor_dists, 
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    cat_outdoor_p1_train, exclude_imgs = sample_partitions(
                                            cat_outdoor_dists,
                                            cat_indoor_dists, 
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    cat_indoor_p0_train, exclude_imgs = sample_partitions(
                                            cat_indoor_dists,
                                            cat_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    cat_indoor_p1_train, exclude_imgs = sample_partitions(
                                            cat_indoor_dists,
                                            cat_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_train_imgs,
                                            exclude_imgs)
    
    
    print("cat_outdoor_p1_train: ", len(cat_outdoor_p0_train))
    print("cat_outdoor_p2_train: ", len(cat_outdoor_p1_train))
    
    print("cat_indoor_p1_train: ", len(cat_indoor_p0_train))
    print("cat_indoor_p2_train: ", len(cat_indoor_p1_train))

    

    ###########################
    # Sampling a validation set
    ###########################
    cat_outdoor_images_val = set(shuffle_and_truncate(test_community_name_to_img_id['cat(outdoor)']) )
    dog_indoor_images_val = set(shuffle_and_truncate(test_community_name_to_img_id['dog(indoor)']) )
    cat_indoor_images_val = set(shuffle_and_truncate(train_community_name_to_img_id['cat(indoor)'])  )
    dog_outdoor_images_val = set(shuffle_and_truncate(train_community_name_to_img_id['dog(outdoor)']))
    
    cat_outdoor_images_val = cat_outdoor_images_val-all_train_imgs-all_test_imgs
    dog_indoor_images_val = dog_indoor_images_val-all_train_imgs-all_test_imgs
    cat_indoor_images_val = cat_indoor_images_val-all_train_imgs-all_test_imgs
    dog_outdoor_images_val = dog_outdoor_images_val-all_train_imgs-all_test_imgs

    all_val_imgs = cat_outdoor_images_val.union(dog_indoor_images_val).union(cat_indoor_images_val).union(dog_outdoor_images_val)
    
    print("remaining images")
    print("cat_outdoor_images_val: ",len(cat_outdoor_images_val))
    print("dog_indoor_images_val: ", len(dog_indoor_images_val))
    print("cat_indoor_images_val: ", len(cat_indoor_images_val))
    print("dog_outdoor_images_val: ", len(dog_outdoor_images_val))

    #### DOGs ###
    exclude_imgs = set()
    max_sub_partition_size = 20 
    max_additional_size = int(max_sub_partition_size*add_p)
    dog_outdoor_p0_val, exclude_imgs = sample_partitions(
                                            dog_outdoor_dists,
                                            dog_indoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs, 
                                            exclude_imgs)
    dog_outdoor_p1_val, exclude_imgs = sample_partitions(
                                            dog_outdoor_dists,
                                            dog_indoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    dog_indoor_p0_val, exclude_imgs = sample_partitions(
                                            dog_indoor_dists,
                                            dog_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    dog_indoor_p1_val, exclude_imgs = sample_partitions(
                                            dog_indoor_dists,
                                            dog_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    
    #### CATs ###
    cat_outdoor_p0_val, exclude_imgs = sample_partitions(
                                            cat_outdoor_dists,
                                            cat_indoor_dists, 
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    cat_outdoor_p1_val, exclude_imgs = sample_partitions(
                                            cat_outdoor_dists,
                                            cat_indoor_dists, 
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    cat_indoor_p0_val, exclude_imgs = sample_partitions(
                                            cat_indoor_dists,
                                            cat_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)
    cat_indoor_p1_val, exclude_imgs = sample_partitions(
                                            cat_indoor_dists,
                                            cat_outdoor_dists,
                                            max_sub_partition_size,
                                            max_additional_size, 
                                            add_p,
                                            node_name_to_img_id,
                                            all_val_imgs,
                                            exclude_imgs)


    print("dog_outdoor_p1_val: ", len(dog_outdoor_p0_val))
    print("dog_outdoor_p2_val: ", len(dog_outdoor_p1_val))
    
    print("dog_indoor_p1_val: ", len(dog_indoor_p0_val))
    print("dog_indoor_p2_val: ", len(dog_indoor_p1_val))

    print("cat_outdoor_p1_val: ", len(cat_outdoor_p0_val))
    print("cat_outdoor_p2_val: ", len(cat_outdoor_p1_val))
    
    print("cat_indoor_p1_val: ", len(cat_indoor_p0_val))
    print("cat_indoor_p2_val: ", len(cat_indoor_p1_val))

    print()
    print(" ==== SAVE to files ==== ")
    SUBPOPULATION_SHIFT_DATASET_FOLDER = args.data_folder
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER, exist_ok = False)
    print("SUBPOPULATION_SHIFT_DATASET_FOLDER: ", SUBPOPULATION_SHIFT_DATASET_FOLDER)
    # exit(0)
    SUBPOPULATION_SHIFT_DATASET_FOLDER_p1 = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/p1'
    SUBPOPULATION_SHIFT_DATASET_FOLDER_p2 = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/p2'
    SUBPOPULATION_SHIFT_DATASET_FOLDER_irm = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/irm'

    ##################
    # * save irm *
    ##################
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat(P1)': cat_indoor_train,
            'cat(P2)': cat_outdoor_train,

            'dog(P1)': dog_indoor_train,
            'dog(P2)': dog_outdoor_train,
            
            'cat(P1)_test' :cat_indoor_test,
            'cat(P2)_test': cat_outdoor_test,
            'dog(P1)_test' :dog_indoor_test,
            'dog(P2)_test': dog_outdoor_test,

            'cat(P1)_val':cat_indoor_p0_val.union(cat_indoor_p1_val),
            'cat(P2)_val' :cat_outdoor_p0_val.union(cat_outdoor_p1_val),
            'dog(P1)_val':dog_indoor_p0_val.union(dog_indoor_p1_val),
            'dog(P2)_val' :dog_outdoor_p0_val.union(dog_outdoor_p1_val),
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_indoor_test.union(cat_outdoor_test)
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'test', 'dog', use_symlink=False,
        img_IDs =  dog_indoor_test.union(dog_outdoor_test)
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  cat_indoor_p0_val.union(cat_indoor_p1_val).union(cat_outdoor_p0_val).union(cat_outdoor_p1_val)
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs = dog_indoor_p0_val.union(dog_indoor_p1_val).union(dog_outdoor_p0_val).union(dog_outdoor_p1_val)
        )
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'cat/cat(P1)', use_symlink=False,
        img_IDs = cat_indoor_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'cat/cat(P2)', use_symlink=False,
        img_IDs = cat_outdoor_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'dog/dog(P1)', use_symlink=False,
        img_IDs = dog_indoor_train
        )  
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'dog/dog(P2)', use_symlink=False,
        img_IDs = dog_outdoor_train
        )    

    ##################
    # * save indoor *
    ##################

    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1 + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat(P11)': cat_indoor_p0_train,
            'cat(P12)': cat_indoor_p1_train,

            'dog(P11)': dog_indoor_p0_train,
            'dog(P12)': dog_indoor_p1_train,
            
            'cat(P1)_test' :cat_indoor_test,
            'dog(P1)_test':dog_indoor_test,

            'cat(P11)_val' :cat_indoor_p0_val,
            'cat(P12)_val': cat_indoor_p1_val,
            'dog(P11)_val' :dog_indoor_p0_val,
            'dog(P12)_val': dog_indoor_p1_val
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_indoor_test
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'test', 'dog', use_symlink=False,
        img_IDs = dog_indoor_test
        )
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  cat_indoor_p0_val.union(cat_indoor_p1_val)
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs = dog_indoor_p0_val.union(dog_indoor_p1_val)
        )

    # plan: 800 training, 
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'cat/cat(P11)', use_symlink=False,
        img_IDs = cat_indoor_p0_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'cat/cat(P12)', use_symlink=False,
        img_IDs = cat_indoor_p1_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'dog/dog(P11)', use_symlink=False,
        img_IDs = dog_indoor_p0_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'dog/dog(P12)', use_symlink=False,
        img_IDs = dog_indoor_p1_train
        )

    ##################
    # * save outdoor *
    ##################
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2 + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat(P21)': cat_outdoor_p0_train,
            'cat(P22)': cat_outdoor_p1_train,

            'dog(P21)': dog_outdoor_p0_train,
            'dog(P22)': dog_outdoor_p1_train,
            
            'cat(P2)_test' :cat_outdoor_test,
            'dog(P2)_test':dog_outdoor_test,

            'cat(P21)_val' :cat_outdoor_p0_val,
            'cat(P22)_val': cat_outdoor_p1_val,
            'dog(P21)_val' :dog_outdoor_p0_val,
            'dog(P22)_val': dog_outdoor_p1_val
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_outdoor_test
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'test', 'dog', use_symlink=False,
        img_IDs = dog_outdoor_test
        )

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  cat_outdoor_p0_val.union(cat_outdoor_p1_val)
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs =  dog_outdoor_p0_val.union(dog_outdoor_p1_val))
    
    # plan: 800 training, 
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'cat/cat(P21)', use_symlink=False,
        img_IDs = cat_outdoor_p0_train
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'cat/cat(P22)', use_symlink=False,
        img_IDs = cat_outdoor_p1_train
        )

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'dog/dog(P21)', use_symlink=False,
        img_IDs = dog_outdoor_p0_train
        )     
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'dog/dog(P22)', use_symlink=False,
        img_IDs = dog_outdoor_p1_train
        )   
    

    return


##################################
# Copy Images specified by IDs: 
# destination folder: os.path.join(root_folder, split, subset_str)
##################################
def copy_images(root_folder,  split, subset_str, img_IDs, use_symlink=True):
    ##################################
    # Create dataset a new folder 
    ##################################
    subject_localgroup_folder = os.path.join(root_folder, split, subset_str)
    if os.path.isdir(subject_localgroup_folder): 
        shutil.rmtree(subject_localgroup_folder) 
    os.makedirs(subject_localgroup_folder, exist_ok = False)

    for image_idx_in_set, imageID in enumerate(img_IDs): 

        src_image_path = IMAGE_DATA_FOLDER + imageID + '.jpg'
        dst_image_path = os.path.join(subject_localgroup_folder, imageID + '.jpg') 

        if use_symlink:
            ##################################
            # Image Copy Option B: create symbolic link
            # Usage: for local use, saving disk storge. 
            ##################################
            os.symlink(src_image_path, dst_image_path)
            # print('symlink:', src_image_path, dst_image_path)
        else:
            ##################################
            # Image Copy Option A: copy the whole jpg file
            # Usage: for sharing the meta-dataset
            ################################## 
            shutil.copyfile(src_image_path, dst_image_path)
            # print('copy:', src_image_path, dst_image_path)

    return 


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='cluster creation')
    parser.add_argument('--images_folder',type=str,default='../../../genome_vision_data/data/GQA/allImages/images/')
    parser.add_argument('--seed', type=int, default=0)
    parser.add_argument('--data_folder', type=str, default='data/MetaShift/subpopulationshift_pirm_ii')
    parser.add_argument('--mp',help='minority_percentage', type=float, default=0.12)
    parser.add_argument('--add_p', type=float, default=0)
    args = parser.parse_args()
    generate_splitted_metadaset(args)

