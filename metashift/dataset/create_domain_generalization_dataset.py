"""

## Section 4.2: Evaluating Subpopulation Shifts
Run the python script `dataset/subpopulation_shift_cat_dog_indoor_outdoor.py` to reproduce the MetaShift subpopulation shift dataset (based on Visual Genome images) in paper Appendix D. 
```sh
cd dataset/
python subpopulation_shift_cat_dog_indoor_outdoor.py
```
The python script generates a “Cat vs. Dog” dataset, where the general contexts “indoor/outdoor” have a natural spurious correlation with the class labels. 


The following files will be generated by executing the python script `dataset/subpopulation_shift_cat_dog_indoor_outdoor.py`. 

### Output files (mixed version: for reproducing experiments)

```plain
/data/MetaShift/MetaShift-subpopulation-shift
├── imageID_to_group.pkl
├── train/
    ├── cat/             (more cat(indoor) images than cat(outdoor))
    ├── dog/             (more dog(outdoor) images than dog(indoor)) 
├── val_out_of_domain/
    ├── cat/             (cat(indoor):cat(outdoor)=1:1)
    ├── dog/             (dog(indoor):dog(outdoor)=1:1) 
```
where `imageID_to_group.pkl` is a dictionary with 4 keys : 
`'cat(outdoor)'`, `'cat(outdoor)'`, `'dog(outdoor)'`, `'dog(outdoor)'`. 
The corresponding value of each key is the list of the names of the images that belongs to that subset. 
You can tune the `NUM_MINORITY_IMG` to control the amount of subpopulation shift.  

### Output files (unmixed version, for other potential uses)
To facilitate other potential uses, we also outputs an unmixed version, where we output the `'cat(outdoor)'`, `'cat(outdoor)'`, `'dog(outdoor)'`, `'dog(outdoor)'` into 4 seperate folders. 
```plain
/data/MetaShift/MetaShift-Cat-Dog-indoor-outdoor
├── imageID_to_group.pkl
├── train/
    ├── cat/             (all cat(indoor) images)
    ├── dog/             (all dog(outdoor) images) 
├── val_out_of_domain/
    ├── cat/             (all cat(outdoor) images)
    ├── dog/             (all dog(indoor) images) 
```

"""

# SUBPOPULATION_SHIFT_DATASET_FOLDER = 'data/MetaShift/MetaShift-subpopulation-shift-expD-ii'


import pandas as pd 
import seaborn as sns

import pickle
import numpy as np
import json, re, math
from collections import Counter, defaultdict
from itertools import repeat
import pprint
import os, errno
from PIL import Image
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import shutil # for copy files
import networkx as nx # graph vis
import pandas as pd
from sklearn.decomposition import TruncatedSVD
import networkx.algorithms.community as nx_comm
import itertools
import random
import argparse
import Constants
import networkx as nx
from sklearn.model_selection import train_test_split
IMAGE_DATA_FOLDER          = Constants.IMAGE_DATA_FOLDER

from generate_full_MetaShift_exp1 import preprocess_groups, build_subset_graph, copy_image_for_subject, build_subset_graph_test


def print_communities(subject_data, node_name_to_img_id, trainsg_dupes, subject_str):
    ##################################
    # Community detection 
    ##################################
    G,Adjacency_matrix = build_subset_graph(subject_data, node_name_to_img_id, trainsg_dupes, subject_str)

    import networkx.algorithms.community as nxcom

    # Find the communities
    communities = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)
    # Count the communities
    print("The graph has {} communities.".format(len(communities)) )
    for community in communities:
        community_merged = set()
        for node_str in community:
            node_str = node_str.replace('\n', '')
            node_image_IDs = node_name_to_img_id[node_str]
            community_merged.update(node_image_IDs)
            # print(node_str , len(node_image_IDs), end=';')

        print('total size:',len(community_merged))
        community_set = set([ x.replace('\n', '') for x in community])
        print(community_set, '\n\n')
    return G 



def parse_dataset_scheme(dataset_scheme, node_name_to_img_id, exclude_img_id=set(), split='test'):
    """
    exclude_img_id contains both trainsg_dupes and test images that we do not want to leak 
    """
    community_name_to_img_id = defaultdict(set)
    all_img_id = set()

    ##################################
    # Iterate subject_str: e.g., cat
    ##################################
    for subject_str in dataset_scheme:        
        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        for community_name in dataset_scheme[subject_str]:
            ##################################
            # Iterate node_name: e.g., 'cat(cup)', 'cat(sofa)', 'cat(chair)'
            ##################################
            for node_name in dataset_scheme[subject_str][community_name]:
                community_name_to_img_id[community_name].update(node_name_to_img_id[node_name] - exclude_img_id)
                all_img_id.update(node_name_to_img_id[node_name] - exclude_img_id)
            print(community_name, 'Size:', len(community_name_to_img_id[community_name]) )


        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        # root_folder = os.path.join(CUSTOM_SPLIT_DATASET_FOLDER, split)
        copy_image_for_subject(root_folder, subject_str, dataset_scheme[subject_str], community_name_to_img_id, trainsg_dupes=set(), use_symlink=False) # use False to share 

    return community_name_to_img_id, all_img_id


def get_all_nodes_in_dataset(dataset_scheme):
    all_nodes = set()
    ##################################
    # Iterate subject_str: e.g., cat
    ##################################
    for subject_str in dataset_scheme:        
        ##################################
        # Iterate community_name: e.g., cat(sofa)
        ##################################
        for community_name in dataset_scheme[subject_str]:
            ##################################
            # Iterate node_name: e.g., 'cat(cup)', 'cat(sofa)', 'cat(chair)'
            ##################################
            for node_name in dataset_scheme[subject_str][community_name]:
                all_nodes.add(node_name)
    return all_nodes

def generate_splitted_metadaset(args):

    SUBPOPULATION_SHIFT_DATASET_FOLDER = args.data_folder
    print("Domain Generalization folder: ", SUBPOPULATION_SHIFT_DATASET_FOLDER)
    
    node_name_to_img_id, most_common_list, subjects_to_all_set, subject_group_summary_dict = preprocess_groups(output_files_flag=False)

    # print(most_common_list)
    # print(subject_group_summary_dict)
    # print()
    # print(subjects_to_all_set.keys())
    common_sub_communities = []
    for cat_comm in subject_group_summary_dict['cat']:
        comm = cat_comm.split('(')[-1][:-1]
        print(comm)
        dog_comm = 'dog('+comm+')'
        if dog_comm in subject_group_summary_dict['dog']:
            common_sub_communities.append(comm)
    print("length: ", len(common_sub_communities))
    print(common_sub_communities)
    
    ##################################
    # Removing ambiguous images that have both cats and dogs 
    ##################################
    trainsg_dupes = node_name_to_img_id['cat(dog)'] # can also use 'dog(cat)'
    subject_str_to_Graphs = dict()


    # for subject_str in ['cat', 'dog']:
    #     subject_data = [ x for x in subject_group_summary_dict[subject_str].keys() if x not in ['cat(dog)', 'dog(cat)'] ]
    #     # print('subject_data', subject_data)
    #     ##################################
    #     # Print detected communities in Meta-Graph
    #     ##################################
    #     G = print_communities(subject_data, node_name_to_img_id, trainsg_dupes, subject_str) # print detected communities, which guides us the train/test split. 
    #     subject_str_to_Graphs[subject_str] = G




    test_set_scheme = {
        'cat': {
            'cat(outdoor)': {
                'cat(car)',
                'cat(fence)', 'cat(grass)', 
                # 'cat(roof)',
                 'cat(bench)', 'cat(bird)', 'cat(house)', 
            },
        },
        'dog': {
            'dog(indoor)': {
                'dog(screen)', 'dog(shelf)', 'dog(desk)', 'dog(picture)', 'dog(laptop)',
                'dog(remote control)', 'dog(blanket)', 'dog(bed)', 'dog(sheet)', 'dog(lamp)', 'dog(books)', 'dog(pillow)', 'dog(curtain)', 
                'dog(container)', 'dog(table)', 'dog(cup)', 'dog(plate)', 'dog(food)', 'dog(box)',
                'dog(rug)', 'dog(floor)', 'dog(cabinet)', 'dog(towel)',
                'dog(bowl)',
                'dog(television)', 'dog(carpet)',
                'dog(sofa)',

            },    
        },    
    }

    train_set_scheme = {
        'cat': {
            'cat(indoor)': {
                'cat(speaker)', 'cat(computer)', 'cat(screen)', 'cat(laptop)', 'cat(computer mouse)', 'cat(keyboard)', 'cat(monitor)', 'cat(desk)',
                'cat(sheet)', 'cat(bed)', 'cat(blanket)', 'cat(remote control)', 'cat(comforter)', 'cat(pillow)', 'cat(couch)',
                'cat(books)', 'cat(book)', 'cat(television)', 'cat(bookshelf)', 'cat(blinds)',
                'cat(sink)', 'cat(bottle)', 'cat(faucet)', 'cat(towel)', 'cat(counter)',
                'cat(curtain)', 'cat(toilet)', 'cat(pot)', 
                'cat(carpet)', 'cat(toy)', 'cat(floor)',
                'cat(plate)', 'cat(rug)', 'cat(food)', 'cat(table)',
                'cat(box)', 'cat(paper)', 'cat(suitcase)', 'cat(bag)',
                'cat(container)', 'cat(vase)', 'cat(shelf)', 'cat(bowl)',
                'cat(picture)', 'cat(papers)', 'cat(lamp)',
                'cat(cup)', 'cat(sofa)', 
            },
        },
        'dog': {
            'dog(outdoor)': {
                'dog(house)', 'dog(grass)', 'dog(horse)', 'dog(fence)', 'dog(cow)', 'dog(sheep)', 'dog(dirt)',
                'dog(car)', 'dog(motorcycle)', 'dog(truck)', 'dog(helmet)', 
                'dog(snow)',
                'dog(flag)', 'dog(boat)', 'dog(rope)', 'dog(trees)', 'dog(frisbee)',
                'dog(bike)', 'dog(bicycle)', 
                'dog(sand)', 'dog(surfboard)', 'dog(water)', 
                'dog(fire hydrant)', 'dog(pole)', 
                'dog(skateboard)',
                'dog(bench)', 'dog(trash can)',
            },
        },
        
    }

    cat = {
        
        'cat(outdoor)': {
            'cat(car)',
            'cat(fence)',
             'cat(grass)', 
            'cat(bench)', 
            'cat(bird)', 
            'cat(house)', 
            'cat(roof)',
            'cat(ground)'
        },
        'cat(indoor)': {
            'cat(sofa)',
            'cat(bed)',
            'cat(blanket)',
            'cat(pillow)',
            # 'cat(keyboard)',
            'cat(shelf)',
            # 'cat(laptop)',
            'cat(carpet)',
            'cat(couch)',
            # 'cat(screen)',
            'cat(box)',
            'cat(book)',
            'cat(picture)',
            'cat(desk)',
            'cat(curtain)',
            'cat(rug)',
            'cat(television)',
            'cat(chair)',
            'cat(lamp)',
            'cat(remote control)',
            'cat(mirror)',
            'cat(bowl)',
            # 'cat(computer)',
            'cat(man)',
            'cat(woman)',
            'cat(person)',
            'cat(door)',
            'cat(table)',
            'cat(floor)',
             'cat(cabinet)',
              'cat(towel)',
              'cat(door)',
            'cat(table)',
            'cat(collar)',
            'cat(shirt)',
            'cat(wall)',
            'cat(window)',
            'cat(hat)',
            'cat(bag)'

        },
    }

    dog = {
        'dog(indoor)': {
            # 'dog(screen)', 'dog(shelf)', 'dog(desk)', 'dog(picture)', 'dog(laptop)',
            # 'dog(remote control)', 'dog(blanket)', 'dog(bed)', 'dog(sheet)', 'dog(lamp)', 'dog(books)', 'dog(pillow)', 'dog(curtain)', 
            #  'dog(table)', 'dog(cup)', 'dog(plate)', 'dog(food)', 'dog(box)',
            # 'dog(rug)', 
            'dog(floor)',
             'dog(cabinet)',
              'dog(towel)',
            'dog(man)'
            'dog(bowl)',
            'dog(carpet)',
            # 'dog(computer)',
            'dog(mirror)',
            'dog(bowl)',
            'dog(sofa)',
            'dog(bed)','dog(blanket)','dog(pillow)',
            # 'dog(keyboard)',
            'dog(shelf)',
            # 'dog(laptop)',
            'dog(carpet)',
            'dog(couch)',
            # 'dog(screen)',
            'dog(box)','dog(book)',
            'dog(picture)',
            'dog(desk)',
            'dog(curtain)',
            'dog(rug)',
            'dog(television)','dog(chair)','dog(lamp)','dog(remote control)',
            'dog(woman)',
            'dog(person)',
            'dog(door)',
            'dog(table)',
            'dog(collar)',
            'dog(shirt)',
            'dog(wall)',
            'dog(window)',
            'dog(hat)',
            'dog(bag)'

        },    
        'dog(outdoor)': {
            'dog(car)',
            'dog(ground)'
            'dog(fence)', 
            'dog(grass)', 
            'dog(bench)',
             'dog(bird)',
             'dog(house)',
            'dog(roof)', 
        }
    }
    additional_test_set_scheme = dict() # empty dict 

    def shuffle_and_truncate(img_id_set, args, truncate=2500):
        img_id_list = sorted(img_id_set)
        random.Random(args.shuffle_seed).shuffle(img_id_list)
        return img_id_list[:truncate]
    

    cat_images = set()
    dog_images = set()
    for comm in common_sub_communities:
        cat_comm = 'cat('+comm+')'
        cat_images.update(node_name_to_img_id[cat_comm]-trainsg_dupes)
        dog_comm = 'dog('+comm+')'
        dog_images.update(node_name_to_img_id[dog_comm]-trainsg_dupes)

    print('cat images: ', len(cat_images))
    print('dog images: ', len(dog_images))
    
    print()
    

    # combine dogs and cats images with shared community under one community name [TRAINING DATA]
    com_to_img_id = {}
    new_sub_comms = []
    for com in common_sub_communities: 
        cat_sub = f'cat({com})'
        dog_sub = f'dog({com})'
        cat_com = node_name_to_img_id[cat_sub].intersection(cat_images)-trainsg_dupes
        dog_com = node_name_to_img_id[dog_sub].intersection(dog_images)-trainsg_dupes
        diff_com = abs(len(cat_com) - len(dog_com))
        # if diff_com < 70:
        cat_com.update(dog_com)
        print("community: ", com, " ",len(cat_com))
        com_to_img_id[com] = cat_com
        new_sub_comms.append(com)
    
    G, animals_clusters, adj_training = build_subset_graph(new_sub_comms, com_to_img_id, trainsg_dupes=trainsg_dupes, subject_str=None, seed=args.seed)
    # animals_outdoor_clusters, adj_training_outdoor = build_subset_graph(sub_outdoor_comms, com_outdoor_to_img_id, trainsg_dupes=trainsg_dupes, subject_str=None)
    print(set(new_sub_comms))
    
    all_cuts = []
    for com in new_sub_comms:
        # print(com)
        all_comms = set(new_sub_comms)-set(com)
        cut_comm = nx.cut_size(G,com,all_comms,weight='weight')
        all_cuts.append(cut_comm)
        # print(cut_comm)
        # print()
    idx_sorted = np.argsort(all_cuts)
    all_cuts = np.array(all_cuts)
    new_sub_comms = np.array(new_sub_comms)
    # print(idx_sorted)
    # print(all_cuts[idx_sorted])
    # print(dict(zip(new_sub_comms[idx_sorted],all_cuts[idx_sorted])))
    
    sub_indoor_comms = animals_clusters[0]
    sub_outdoor_comms = animals_clusters[1]

    disparity = []
    lens = []
    diffs = []
    for com in new_sub_comms:
        cat_sub = f'cat({com})'
        dog_sub = f'dog({com})'
        cat_com = node_name_to_img_id[cat_sub].intersection(cat_images)-trainsg_dupes
        dog_com = node_name_to_img_id[dog_sub].intersection(dog_images)-trainsg_dupes
        cat_com.update(dog_com)
        diff_com = abs(len(cat_com) - len(dog_com))
        diffs.append(diff_com)
        lens.append(len(cat_com))
        # print("community: ", com, " ",len(cat_com))
        # print(com)
        all_comms = set(sub_indoor_comms)-set(com)
        cut_in = nx.cut_size(G,com,all_comms,weight='weight')

        all_comms = set(sub_outdoor_comms)-set(com)
        cut_out = nx.cut_size(G,com,all_comms,weight='weight')

        # print(f"{com} | {cut_in} | {cut_out}")
        disparity.append(cut_in - cut_out)
    idx_disp = np.argsort(disparity)
    disparity = np.array(disparity)
    lens = np.array(lens)
    diffs = np.array(diffs)
    for i,j,z, f in zip(new_sub_comms[idx_disp],disparity[idx_disp], lens[idx_disp], diffs[idx_disp]):
        print(f"{i} | disparity: {j} | size: {z} | diff: {f}")
    
    # test_envs = ["floor","shelf","bag","door"]
    test_envs = ["fence","shelf","woman","floor"]
    for com in test_envs:
        print(com)
        cat_sub = f'cat({com})'
        dog_sub = f'dog({com})'
        cat_com = node_name_to_img_id[cat_sub].intersection(cat_images)-trainsg_dupes
        dog_com = node_name_to_img_id[dog_sub].intersection(dog_images)-trainsg_dupes
        print("cats: ",len(cat_com))
        print("dogs: ",len(dog_com))
    
    training_sub_comms = set(new_sub_comms)-set(test_envs)
    G_train, animals_clusters, adj_training = build_subset_graph(training_sub_comms, com_to_img_id, trainsg_dupes=trainsg_dupes, subject_str=None, seed=args.seed)
    
    sub_indoor_comms = animals_clusters[0]
    sub_outdoor_comms = animals_clusters[1]

    G_in, animals_indoor_clusters, adj_training_indoor = build_subset_graph(sub_indoor_comms, com_to_img_id, trainsg_dupes=trainsg_dupes, subject_str=None,seed=args.seed)
    G_out, animals_outdoor_clusters, adj_training_outdoor = build_subset_graph(sub_outdoor_comms, com_to_img_id, trainsg_dupes=trainsg_dupes, subject_str=None,seed=args.seed)
    # print(G_in.edges(data=True))
    # exit(0)
    # print("number of communities in env 1: ", len(animals_indoor_clusters[0]), len(animals_indoor_clusters[1]))
    # print("number of communities in env 2", len(animals_outdoor_clusters[0]), len(animals_outdoor_clusters[1]))

    animals_indoor_clusters = [
        ['pot', 'curtain', 'chair', 'bottle', 'laptop', 'plate', 'desk',
       'food', 'television', 'vase', 'screen', 'bowl', 'cup', 'book',
       'window', 'monitor', 'refrigerator', 'box', 'clock', 'toy', 'door',
       'cell phone', 'picture', 'phone', 'shelf', 'wall', 'mat', 'drawer',
       'table', 'toilet', 'coffee table', 'books', 'towel', 'rug',
       'carpet', 'keyboard', 'cabinet', 'container'],
        ['pillow', 'lamp', 'sheet', 'blanket', 'remote control', 'pillows',
       'teddy bear', 'bed', 'comforter', 'couch', 'sofa', 'suitcase']
       ]
    animals_outdoor_clusters = [
        ['collar', 'man', 'glasses', 'purse', 'animal', 'hat', 'horse',
       'girl', 'bag', 'woman', 'boy', 'ball', 'house', 'ground', 'water',
       'bench', 'person', 'bird', 'fence', 'lady', 'backpack', 'umbrella',
       'bicycle'], 
       ['motorcycle', 'bike', 'car', 'mirror', 'camera', 'seat']
       ]

    print("FIXED CLUSTERS ")
    print("number of communities in env 1: ", len(animals_indoor_clusters[0]), len(animals_indoor_clusters[1]))
    print("number of communities in env 2", len(animals_outdoor_clusters[0]), len(animals_outdoor_clusters[1]))


    overlap_len = args.overlap_len
    minority_percentage = args.minority_percentage

    
    sub_test_size = 50
    sub_val_prop = 0.3

    all_cat_test = set()
    all_dog_test = set()

    outdoor_partition_dict_test = {}
    indoor_partition_dict_test = {}

    test_ids = []
    for ac, com in enumerate(test_envs):
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        sub_cat = f'cat({com})'
        sub_dog = f'dog({com})'

        sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(cat_images))
        sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes-all_cat_test)

        sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(dog_images))
        sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes-all_dog_test)
        
        cat_test = set(shuffle_and_truncate(sub_cat_imgs,args,sub_test_size))
        dog_test = set(shuffle_and_truncate(sub_dog_imgs,args,sub_test_size))
        
        # min_test = min(len(cat_test),len(dog_test))

        # cat_test = set(shuffle_and_truncate(cat_test,args,min_test))
        # dog_test = set(shuffle_and_truncate(dog_test,args,min_test))
        
        all_cat_test.update(cat_test)
        all_dog_test.update(dog_test)

        print("total cats test: ", len(cat_test))
        print("total dogs test: ", len(dog_test))
        indoor_partition_dict_test[f"cat_{ac}"] = cat_test
        indoor_partition_dict_test[f"dog_{ac}"] = dog_test
        test_ids.append(ac)

       

    print("total cats test: ", len(all_cat_test))
    print("total dogs test: ", len(all_dog_test))

    all_cat_val = set()
    all_dog_val = set()

    all_cat_train = set()
    all_dog_train = set()
    

    env_name = 'indoor'
    animals = ['cat','dog']
    print("indoor clusters, ",len(animals_indoor_clusters))
    
    indoor_partition_dict = {}
    # indoor_partition_dict_test = {}
    indoor_partition_dict_val = {}

    p_size = []
    p_size_val = []
    for ac, animal_cluster in enumerate(animals_indoor_clusters):
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        for com in animal_cluster:
            sub_cat = f'cat({com})'
            sub_dog = f'dog({com})'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(cat_images))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(dog_images))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)

        
        total_clust+=len(sub_dog_imgs)
        total_clust+=len(sub_cat_imgs)
        print(f"indoor p {ac}: ",total_clust)


        sub_cat_val_size = int(len(sub_cat_imgs-all_cat_train-all_cat_val-all_cat_test)*sub_val_prop)
        sub_dog_val_size = int(len(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val)*sub_val_prop)
        sub_val_size = min(sub_cat_val_size,sub_dog_val_size )

        # Cats
        # cat_test = set(shuffle_and_truncate(sub_cat_imgs-all_cat_train-all_cat_test-all_cat_val,args,sub_test_size))
        # all_cat_test.update(cat_test)
        cat_val = set(shuffle_and_truncate(sub_cat_imgs-all_cat_train-all_cat_test-all_cat_val,args,sub_val_size))
        all_cat_val.update(cat_val)

        cat_train = set(sub_cat_imgs)-all_cat_test-all_cat_val-all_cat_train
        
        ### Dogs
        # dog_test = set(shuffle_and_truncate(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val,args,sub_test_size))
        # all_dog_test.update(dog_test)
        dog_val = set(shuffle_and_truncate(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val,args,sub_val_size))
        all_dog_val.update(dog_val)

        dog_train = set(sub_dog_imgs)-all_dog_test-all_dog_val-all_dog_train

        min_trunc = min(len(dog_train), len(cat_train))
        cat_train = set(shuffle_and_truncate(list(cat_train),args,min_trunc))
        dog_train = set(shuffle_and_truncate(list(dog_train),args, min_trunc))

        all_cat_train.update(cat_train)
        all_dog_train.update(dog_train)

        print("cat test: ",len(cat_test))
        print("cat val: ", len(cat_val))
        print("cat train", len(cat_train))

        indoor_partition_dict[f"cat_p{ac}"] = cat_train
        indoor_partition_dict[f"dog_p{ac}"] = dog_train

        # indoor_partition_dict_test[f"cat_p{ac}"] = cat_test
        # indoor_partition_dict_test[f"dog_p{ac}"] = dog_test

        indoor_partition_dict_val[f"cat_p{ac}"] = cat_val
        indoor_partition_dict_val[f"dog_p{ac}"] = dog_val


        p_size.append(len(cat_train)+len(dog_train))
        p_size_val.append(len(cat_val)+len(dog_val))
        print("dog test: ",len(dog_test))
        print("dog val: ", len(dog_val))
        print("dog train", len(dog_train))

    # max_p = np.argmax(p_size)
    # min_p = np.argmin(p_size)
    # # print("max partition size: ",max_p, p_size[max_p])
    # new_size = int(p_size[max_p]/2*minority_percentage)+1
    # indoor_partition_dict[f'cat_p{min_p}'] = set(shuffle_and_truncate(indoor_partition_dict[f'cat_p{min_p}'],args,new_size))
    # indoor_partition_dict[f'dog_p{min_p}'] = set(shuffle_and_truncate(indoor_partition_dict[f'dog_p{min_p}'],args,new_size))

    # new_size = int(p_size_val[max_p]/2*minority_percentage)+1
    # indoor_partition_dict_val[f'cat_p{min_p}'] = set(shuffle_and_truncate(indoor_partition_dict_val[f'cat_p{min_p}'],args,new_size))
    # indoor_partition_dict_val[f'dog_p{min_p}'] = set(shuffle_and_truncate(indoor_partition_dict_val[f'dog_p{min_p}'],args,new_size))


    env_name = 'outdoor'
    print("outdoor clusters, ",len(animals_outdoor_clusters))
    outdoor_partition_dict = {}
    # outdoor_partition_dict_test = {}
    outdoor_partition_dict_val = {}
    p_size = []
    p_size_val = []
    for ac, animal_cluster in enumerate(animals_outdoor_clusters):
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        for com in animal_cluster:
            sub_cat = 'cat('+com+')'
            sub_dog = 'dog('+com+')'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(cat_images))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(dog_images))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)

        total_clust+=len(sub_dog_imgs)
        total_clust+=len(sub_cat_imgs)
        print(f"outdoor p {ac}: ",total_clust)
        
        ## Cats
        # cat_test = set(shuffle_and_truncate(sub_cat_imgs-all_cat_train-all_cat_test-all_cat_val,args,sub_test_size))
        # all_cat_test.update(cat_test)
        sub_cat_val_size = int(len(sub_cat_imgs-all_cat_train-all_cat_val-all_cat_test)*sub_val_prop)
        sub_dog_val_size = int(len(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val)*sub_val_prop)
        sub_val_size = min(sub_cat_val_size,sub_dog_val_size )

        cat_val = set(shuffle_and_truncate(sub_cat_imgs-all_cat_train-all_cat_val-all_cat_test,args,sub_val_size))
        all_cat_val.update(cat_val)

        cat_train = set(sub_cat_imgs)-all_cat_test-all_cat_val-all_cat_train
        

        ## Dogs
        # dog_test = set(shuffle_and_truncate(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val,args,sub_test_size))
        # all_dog_test.update(dog_test)
        sub_val_size = int(len(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val)*sub_val_prop)
        dog_val = set(shuffle_and_truncate(sub_dog_imgs-all_dog_train-all_dog_test-all_dog_val,args,sub_val_size))
        all_dog_val.update(dog_val)

        dog_train = set(sub_dog_imgs)-all_dog_test-all_dog_val-all_dog_train
        

        min_trunc = min(len(dog_train), len(cat_train))
        cat_train = set(shuffle_and_truncate(list(cat_train),args,min_trunc))
        dog_train = set(shuffle_and_truncate(list(dog_train),args, min_trunc))
        
        all_cat_train.update(cat_train)
        all_dog_train.update(dog_train)

        print("cat test: ",len(cat_test))
        print("cat val: ", len(cat_val))
        print("cat train", len(cat_train))

        print("dog test: ",len(dog_test))
        print("dog val: ", len(dog_val))
        print("dog train", len(dog_train))
            
        outdoor_partition_dict[f"cat_p{ac}"] = cat_train
        outdoor_partition_dict[f"dog_p{ac}"] = dog_train
        
        # outdoor_partition_dict_test[f"cat_p{ac}"] = cat_test
        # outdoor_partition_dict_test[f"dog_p{ac}"] = dog_test

        outdoor_partition_dict_val[f"cat_p{ac}"] = cat_val
        outdoor_partition_dict_val[f"dog_p{ac}"] = dog_val

        
        p_size.append(len(cat_train)+len(dog_train))
        p_size_val.append(len(cat_val)+len(dog_val))
    
    # max_p = np.argmax(p_size)
    # min_p = np.argmin(p_size)
    # print("max partition size: ",max_p, p_size[max_p])
    # new_size = int(p_size[max_p]/2*minority_percentage)+1
    
    # outdoor_partition_dict[f'cat_p{min_p}'] = set(shuffle_and_truncate(outdoor_partition_dict[f'cat_p{min_p}'],args,new_size))
    # outdoor_partition_dict[f'dog_p{min_p}'] = set(shuffle_and_truncate(outdoor_partition_dict[f'dog_p{min_p}'],args,new_size))

    # new_size = int(p_size_val[max_p]/2*minority_percentage)+1

    # outdoor_partition_dict_val[f'cat_p{min_p}'] = set(shuffle_and_truncate(outdoor_partition_dict_val[f'cat_p{min_p}'],args,new_size))
    # outdoor_partition_dict_val[f'dog_p{min_p}'] = set(shuffle_and_truncate(outdoor_partition_dict_val[f'dog_p{min_p}'],args,new_size))

    
    #### extract validation set for grid search ####
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER, exist_ok = False)
    print("SUBPOPULATION_SHIFT_DATASET_FOLDER: ", SUBPOPULATION_SHIFT_DATASET_FOLDER)
    # exit(0)
    SUBPOPULATION_SHIFT_DATASET_FOLDER_p1 = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/p1'
    SUBPOPULATION_SHIFT_DATASET_FOLDER_p2 = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/p2'
    SUBPOPULATION_SHIFT_DATASET_FOLDER_irm = SUBPOPULATION_SHIFT_DATASET_FOLDER+'/irm'
    
    ##################
    # * save irm *
    ##################
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_irm + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat_indoor_p0': indoor_partition_dict['cat_p0'],
            'cat_indoor_p1': indoor_partition_dict['cat_p1'],

            'dog_indoor_p0': indoor_partition_dict['dog_p0'],
            'dog_indoor_p1': indoor_partition_dict['dog_p1'],
            
            f'cat_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['cat_0'],
            f'cat_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['cat_1'],
            f'cat_outdoor_{test_envs[2]}_test': indoor_partition_dict_test['cat_2'],
            f'cat_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['cat_3'],
            
            f'dog_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['dog_0'],
            f'dog_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['dog_1'],
            f'dog_outdoor_{test_envs[2]}_test' :indoor_partition_dict_test['dog_2'],
            f'dog_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['dog_3'],

            'cat_indoor_p0_val' :indoor_partition_dict_val['cat_p0'],
            'cat_indoor_p1_val': indoor_partition_dict_val['cat_p1'],
            'dog_indoor_p0_val' :indoor_partition_dict_val['dog_p0'],
            'dog_indoor_p1_val': indoor_partition_dict_val['dog_p1'],

            'cat_outdoor_p0': outdoor_partition_dict['cat_p0'],
            'cat_outdoor_p1': outdoor_partition_dict['cat_p1'],

            'dog_outdoor_p0': outdoor_partition_dict['dog_p0'],
            'dog_outdoor_p1': outdoor_partition_dict['dog_p1'],
            
            # 'cat_outdoor_p0_test' :outdoor_partition_dict_test['cat_p0'],
            # 'cat_outdoor_p1_test': outdoor_partition_dict_test['cat_p1'],
            # 'dog_outdoor_p0_test' :outdoor_partition_dict_test['dog_p0'],
            # 'dog_outdoor_p1_test': outdoor_partition_dict_test['dog_p1'],

            'cat_outdoor_p0_val' :outdoor_partition_dict_val['cat_p0'],
            'cat_outdoor_p1_val': outdoor_partition_dict_val['cat_p1'],
            'dog_outdoor_p0_val' :outdoor_partition_dict_val['dog_p0'],
            'dog_outdoor_p1_val': outdoor_partition_dict_val['dog_p1'],
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)
    cat_test_imgs = set()
    for x in test_ids:
        cat_test_imgs = cat_test_imgs.union(indoor_partition_dict_test[f"cat_{x}"])
    dog_test_imgs = set()
    for x in test_ids:
        dog_test_imgs = dog_test_imgs.union(indoor_partition_dict_test[f"dog_{x}"])
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_test_imgs)
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'test', 'dog', use_symlink=False,
        img_IDs = dog_test_imgs)

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  indoor_partition_dict_val['cat_p0'].union(indoor_partition_dict_val['cat_p1']).union(outdoor_partition_dict_val['cat_p0']).union(outdoor_partition_dict_val['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs = indoor_partition_dict_val['dog_p0'].union(indoor_partition_dict_val['dog_p1']).union(outdoor_partition_dict_val['dog_p0']).union(outdoor_partition_dict_val['dog_p1'])
        )
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'cat', use_symlink=False,
        img_IDs = indoor_partition_dict['cat_p0'].union(indoor_partition_dict['cat_p1']).union(outdoor_partition_dict['cat_p0']).union(outdoor_partition_dict['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_irm, 'train', 'dog', use_symlink=False,
        img_IDs = outdoor_partition_dict['dog_p0'].union(outdoor_partition_dict['dog_p1']).union(indoor_partition_dict['dog_p0']).union(indoor_partition_dict['dog_p1'])
        )    

    
    
    
    # env 1 partitions
    p1, p2 = list(animals_indoor_clusters[0]), list(animals_indoor_clusters[1])
    tmp_p = list(p1)
    new_comms = []
    if overlap_len > 0:
        for i in range(overlap_len):
            min_cuts = []
            for pp in tmp_p: 
                mc = nx.cut_size(G_in, pp,p2,weight='weight')
                min_cuts.append(mc)
            max_cut = np.argmax(min_cuts)
            new_comms.append(tmp_p[max_cut])
            p2.append(tmp_p[max_cut])
            tmp_p.pop(max_cut)
        # indoor_partition_dict[f"cat_p{ac}"] = cat_train
        # indoor_partition_dict[f"dog_p{ac}"] = dog_train
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        ac = 1
        print("LEN OF P11: ", len(indoor_partition_dict[f"cat_p0"]))
        for com in new_comms:
            sub_cat = 'cat('+com+')'
            sub_dog = 'dog('+com+')'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(indoor_partition_dict[f"cat_p{ac}"]))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(indoor_partition_dict[f"dog_p{ac}"]))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)
        sub_cat_imgs_p0 = sub_cat_imgs
        sub_dog_imgs_p1 = sub_dog_imgs
        
        new_comms = []
        tmp_p = list(p2)
        # print("p1 indoor: ", p1)
        for i in range(overlap_len):
            min_cuts = []
            for pp in tmp_p: 
                mc = nx.cut_size(G_in, pp,p1,weight='weight')
                min_cuts.append(mc)
            max_cut = np.argmax(min_cuts)
            p1.append(tmp_p[max_cut])
            new_comms.append(tmp_p[max_cut])
            tmp_p.pop(max_cut)
        animals_indoor_clusters = [p1, p2]
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        ac = 0
        for com in new_comms:
            sub_cat = 'cat('+com+')'
            sub_dog = 'dog('+com+')'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(indoor_partition_dict[f"cat_p{ac}"]))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(indoor_partition_dict[f"dog_p{ac}"]))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)
        
        ac = 0
        indoor_partition_dict[f"cat_p{ac}"].update(sub_cat_imgs_p0)
        indoor_partition_dict[f"dog_p{ac}"].update(sub_dog_imgs_p1)

        ac = 1
        indoor_partition_dict[f"cat_p{ac}"].update(sub_cat_imgs)
        indoor_partition_dict[f"dog_p{ac}"].update(sub_dog_imgs)


        # env 2 paritions
        p1, p2 = list(animals_outdoor_clusters[0]), list(animals_outdoor_clusters[1])
        tmp_p = list(p1)
        new_comms = []
        for i in range(overlap_len):
            min_cuts = []
            for pp in tmp_p: 
                mc = nx.cut_size(G_out, pp,p2,weight='weight')
                min_cuts.append(mc)
            max_cut = np.argmax(min_cuts)
            p2.append(tmp_p[max_cut])
            new_comms.append(tmp_p[max_cut])
            tmp_p.pop(max_cut)
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        ac = 1
        for com in new_comms:
            sub_cat = 'cat('+com+')'
            sub_dog = 'dog('+com+')'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(outdoor_partition_dict[f"cat_p{ac}"]))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(outdoor_partition_dict[f"dog_p{ac}"]))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)
        sub_cat_imgs_p0 = sub_cat_imgs
        sub_dog_imgs_p0 = sub_dog_imgs
        
        new_comms = [] 
        tmp_p = list(p2)
        for i in range(overlap_len):
            min_cuts = []
            for pp in tmp_p: 
                mc = nx.cut_size(G_out, pp,p1,weight='weight')
                min_cuts.append(mc)
            max_cut = np.argmax(min_cuts)
            p1.append(tmp_p[max_cut])
            new_comms.append(tmp_p[max_cut])
            tmp_p.pop(max_cut)

        animals_outdoor_clusters = [p1, p2]
        sub_cat_imgs = set()
        sub_dog_imgs = set()
        total_clust = 0
        ac = 0
        for com in new_comms:
            sub_cat = 'cat('+com+')'
            sub_dog = 'dog('+com+')'

            sub_cat_imgs.update(node_name_to_img_id[sub_cat].intersection(outdoor_partition_dict[f"cat_p{ac}"]))
            sub_cat_imgs.update(sub_cat_imgs-trainsg_dupes)

            sub_dog_imgs.update(node_name_to_img_id[sub_dog].intersection(outdoor_partition_dict[f"dog_p{ac}"]))
            sub_dog_imgs.update(sub_dog_imgs-trainsg_dupes)
        ac = 0
        outdoor_partition_dict[f"cat_p{ac}"].update(sub_cat_imgs_p0)
        outdoor_partition_dict[f"dog_p{ac}"].update(sub_dog_imgs_p0)
        
        ac = 1
        outdoor_partition_dict[f"cat_p{ac}"].update(sub_cat_imgs)
        outdoor_partition_dict[f"dog_p{ac}"].update(sub_dog_imgs)

        # print("LEN OF P11: ", len(indoor_partition_dict[f"cat_p0"]))
        
    
    print(animals_indoor_clusters)
    print(animals_outdoor_clusters)
    print("number of communities in env 1: ", len(animals_indoor_clusters[0]), len(animals_indoor_clusters[1]))
    print("number of communities in env 2", len(animals_outdoor_clusters[0]), len(animals_outdoor_clusters[1]))

    
    cat_train = indoor_partition_dict['cat_p0'].union(indoor_partition_dict['cat_p1']).union(outdoor_partition_dict['cat_p0']).union(outdoor_partition_dict['cat_p1'])
    dog_train = indoor_partition_dict['dog_p0'].union(indoor_partition_dict['dog_p1']).union(outdoor_partition_dict['dog_p0']).union(outdoor_partition_dict['dog_p1'])

    # cat_test = indoor_partition_dict_test['cat_p0'].union(indoor_partition_dict_test['cat_p1']).union(outdoor_partition_dict_test['cat_p0']).union(outdoor_partition_dict_test['cat_p1'])
    # dog_test = indoor_partition_dict_test['dog_p0'].union(indoor_partition_dict_test['dog_p1']).union(outdoor_partition_dict_test['dog_p0']).union(outdoor_partition_dict_test['dog_p1'])

    print(" *** New sizes: ",)
    print('cluster A.1: ', len(indoor_partition_dict['cat_p0'])+len(indoor_partition_dict['dog_p0']))
    print('cluster A.2: ',  len(indoor_partition_dict['cat_p1'])+len(indoor_partition_dict['dog_p1']))
    print('cluster B.1: ',  len(outdoor_partition_dict['cat_p0'])+len(outdoor_partition_dict['dog_p0']))
    print('cluster B.2: ', len(outdoor_partition_dict['cat_p1'])+len(outdoor_partition_dict['dog_p1']))

    print(" ** val size: **")
    print('cluster A.1: ', len(indoor_partition_dict_val['cat_p0'])+len(indoor_partition_dict_val['dog_p0']))
    print('cluster A.2: ',  len(indoor_partition_dict_val['cat_p1'])+len(indoor_partition_dict_val['dog_p1']))
    print('cluster B.1: ',  len(outdoor_partition_dict_val['cat_p0'])+len(outdoor_partition_dict_val['dog_p0']))
    print('cluster B.2: ', len(outdoor_partition_dict_val['cat_p1'])+len(outdoor_partition_dict_val['dog_p1']))

    # print(" ** test size: **")
    # print('cluster A.1: ', len(indoor_partition_dict_test['cat_p0'])+len(indoor_partition_dict_test['dog_p0']))
    # print('cluster A.2: ',  len(indoor_partition_dict_test['cat_p1'])+len(indoor_partition_dict_test['dog_p1']))
    # print('cluster B.1: ',  len(outdoor_partition_dict_test['cat_p0'])+len(outdoor_partition_dict_test['dog_p0']))
    # print('cluster B.2: ', len(outdoor_partition_dict_test['cat_p1'])+len(outdoor_partition_dict_test['dog_p1']))
    

    ### Re-evaluate distances
    aindoors = animals_indoor_clusters[0]
    aindoors.extend(animals_indoor_clusters[1])
    sub_indoor_comms = aindoors

    aoutdoors = animals_outdoor_clusters[0]
    aoutdoors.extend(animals_outdoor_clusters[1])
    sub_outdoor_comms = aoutdoors
    print()
    print("re-evaluate dists")
    for com in test_envs:
        all_comms = set(sub_indoor_comms)-set(com)
        cut_in = nx.cut_size(G,com,all_comms,weight='weight')

        all_comms = set(sub_outdoor_comms)-set(com)
        cut_out = nx.cut_size(G,com,all_comms,weight='weight')

        all_comms = set(sub_outdoor_comms).union(set(sub_indoor_comms))-set(com)
        cut_total = nx.cut_size(G,com,all_comms,weight='weight')

        print(f"{com}: total similarity: {cut_total} | dist_e1 = {cut_in} | dist_e2 = {cut_out}")    

    

    #### save minority group keys #####

    p11 = len(indoor_partition_dict['cat_p0'])+len(indoor_partition_dict['dog_p0'])
    p12 = len(indoor_partition_dict['cat_p1'])+len(indoor_partition_dict['dog_p1'])
    p1 = [p11,p12]

    p21 = len(outdoor_partition_dict['cat_p0'])+len(outdoor_partition_dict['dog_p0'])
    p22 = len(outdoor_partition_dict['cat_p1'])+len(outdoor_partition_dict['dog_p1'])
    p2 = [p21,p22]

    env1_min = np.argmin(p1)
    env2_min = np.argmin(p2)
    minorities = {f"p_{env1_min}", f"p_{env2_min}"}
    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER+ '/'+'minority_groups.pkl','wb') as f:
        pickle.dump(minorities, file=f)

    ##################
    # * save indoor *
    ##################

    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_p1 + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat_p0': indoor_partition_dict['cat_p0'],
            'cat_p1': indoor_partition_dict['cat_p1'],

            'dog_p0': indoor_partition_dict['dog_p0'],
            'dog_p1': indoor_partition_dict['dog_p1'],
            
            f'cat_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['cat_0'],
            f'cat_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['cat_1'],
            f'cat_outdoor_{test_envs[2]}_test': indoor_partition_dict_test['cat_2'],
            f'cat_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['cat_3'],
            
            f'dog_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['dog_0'],
            f'dog_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['dog_1'],
            f'dog_outdoor_{test_envs[2]}_test' :indoor_partition_dict_test['dog_2'],
            f'dog_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['dog_3'],


            'cat_p0_val' :indoor_partition_dict_val['cat_p0'],
            'cat_p1_val': indoor_partition_dict_val['cat_p1'],
            'dog_p0_val' :indoor_partition_dict_val['dog_p0'],
            'dog_p1_val': indoor_partition_dict_val['dog_p1']
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)
    # cat_test_imgs = set()
    # for x in test_ids:
    #     cat_test_imgs = cat_test_imgs.union(indoor_partition_dict_test[f"cat_{x}"])
    # dog_test_imgs = set()
    # for x in test_ids:
    #     dog_test_imgs = dog_test_imgs.union(indoor_partition_dict_test[f"dog_{x}"])
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_test_imgs)
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'test', 'dog', use_symlink=False,
        img_IDs = dog_test_imgs)
    
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  indoor_partition_dict_val['cat_p0'].union(indoor_partition_dict_val['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs = indoor_partition_dict_val['dog_p0'].union(indoor_partition_dict_val['dog_p1'])
        )

    # plan: 800 training, 
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'cat', use_symlink=False,
        img_IDs = indoor_partition_dict['cat_p0'].union(indoor_partition_dict['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p1, 'train', 'dog', use_symlink=False,
        img_IDs = indoor_partition_dict['dog_p0'].union(indoor_partition_dict['dog_p1'])
        )

    ##################
    # * save outdoor *
    ##################
    if os.path.isdir(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2): 
        shutil.rmtree(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2) 
    os.makedirs(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, exist_ok = False)

    with open(SUBPOPULATION_SHIFT_DATASET_FOLDER_p2 + '/' + 'imageID_to_group.pkl', 'wb') as handle:
        imageID_to_group = dict()
        group_to_imageID = {
            'cat_p0': outdoor_partition_dict['cat_p0'],
            'cat_p1': outdoor_partition_dict['cat_p1'],

            'dog_p0': outdoor_partition_dict['dog_p0'],
            'dog_p1': outdoor_partition_dict['dog_p1'],
            
            f'cat_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['cat_0'],
            f'cat_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['cat_1'],
            f'cat_outdoor_{test_envs[2]}_test': indoor_partition_dict_test['cat_2'],
            f'cat_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['cat_3'],
            
            f'dog_indoor_{test_envs[0]}_test' :indoor_partition_dict_test['dog_0'],
            f'dog_outdoor_{test_envs[1]}_test': indoor_partition_dict_test['dog_1'],
            f'dog_outdoor_{test_envs[2]}_test' :indoor_partition_dict_test['dog_2'],
            f'dog_outdoor_{test_envs[3]}_test': indoor_partition_dict_test['dog_3'],


            'cat_p0_val' :outdoor_partition_dict_val['cat_p0'],
            'cat_p1_val': outdoor_partition_dict_val['cat_p1'],
            'dog_p0_val' :outdoor_partition_dict_val['dog_p0'],
            'dog_p1_val': outdoor_partition_dict_val['dog_p1']
        }
        for group_str in group_to_imageID:
            for imageID in group_to_imageID[group_str]:
                if imageID not in imageID_to_group:
                    imageID_to_group[imageID] = [group_str] 
                else:
                    imageID_to_group[imageID].append(group_str)
        pickle.dump(imageID_to_group, file=handle)

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'test', 'cat', use_symlink=False,
        img_IDs =  cat_test_imgs)
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'test', 'dog', use_symlink=False,
        img_IDs = dog_test_imgs)

    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'val_out_of_domain', 'cat', use_symlink=False,
        img_IDs =  outdoor_partition_dict_val['cat_p0'].union(outdoor_partition_dict_val['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'val_out_of_domain', 'dog', use_symlink=False,
        img_IDs = outdoor_partition_dict_val['dog_p0'].union(outdoor_partition_dict_val['dog_p1'])
        )
    
    # plan: 800 training, 
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'cat', use_symlink=False,
        img_IDs = outdoor_partition_dict['cat_p0'].union(outdoor_partition_dict['cat_p1'])
        )
    copy_images(
        SUBPOPULATION_SHIFT_DATASET_FOLDER_p2, 'train', 'dog', use_symlink=False,
        img_IDs =outdoor_partition_dict['dog_p0'].union(outdoor_partition_dict['dog_p1'])
        )    

    
    
    return


##################################
# Copy Images specified by IDs: 
# destination folder: os.path.join(root_folder, split, subset_str)
##################################
def copy_images(root_folder,  split, subset_str, img_IDs, use_symlink=True):
    ##################################
    # Create dataset a new folder 
    ##################################
    subject_localgroup_folder = os.path.join(root_folder, split, subset_str)
    if os.path.isdir(subject_localgroup_folder): 
        shutil.rmtree(subject_localgroup_folder) 
    os.makedirs(subject_localgroup_folder, exist_ok = False)

    for image_idx_in_set, imageID in enumerate(img_IDs): 

        src_image_path = IMAGE_DATA_FOLDER + imageID + '.jpg'
        dst_image_path = os.path.join(subject_localgroup_folder, imageID + '.jpg') 

        if use_symlink:
            ##################################
            # Image Copy Option B: create symbolic link
            # Usage: for local use, saving disk storge. 
            ##################################
            os.symlink(src_image_path, dst_image_path)
            # print('symlink:', src_image_path, dst_image_path)
        else:
            ##################################
            # Image Copy Option A: copy the whole jpg file
            # Usage: for sharing the meta-dataset
            ################################## 
            shutil.copyfile(src_image_path, dst_image_path)
            # print('copy:', src_image_path, dst_image_path)

    return 


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='cluster creation')
    parser.add_argument('--seed', type=int, default=0)
    parser.add_argument('--data_folder', type=str, default='data/MetaShift/MetaShift-domain-generalization-expG')
    parser.add_argument('--shuffle_seed', type=str, default=42)
    parser.add_argument('--minority_percentage', type=float, default=1)
    parser.add_argument('--overlap_len', type=int, default=0)
    args = parser.parse_args()
    generate_splitted_metadaset(args)

