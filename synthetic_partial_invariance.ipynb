{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7ktmxTyzMfdM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from scipy.stats import ortho_group"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### more helpers\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch import autograd\n",
        "import time\n",
        "import argparse\n",
        "import random\n",
        "import copy\n",
        "from argparse import Namespace"
      ],
      "metadata": {
        "id": "IXmuugD2c0dQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 230\n",
        "\n",
        "torch.random.manual_seed(i)\n",
        "torch.manual_seed(i)\n",
        "random.seed(i)\n",
        "np.random.seed(i)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "k_fj0nQ2nsoA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generative_model(e_tr, x_dim = 10, heteroskedastic = False, scrambled = False, partially_obs = False):\n",
        "    \n",
        "    list_envs = []\n",
        "    if partially_obs:\n",
        "        w_h_x = np.random.normal(size=(2, x_dim, x_dim))/x_dim\n",
        "        w_h_y = np.random.normal(size=(x_dim, 1))/np.sqrt(x_dim)\n",
        "    else:\n",
        "        w_h_x = np.zeros((2, x_dim, x_dim))\n",
        "        w_h_y = np.zeros((x_dim, 1))\n",
        "    \n",
        "    if scrambled:\n",
        "        S = ortho_group.rvs(dim=2*x_dim)\n",
        "    else:\n",
        "        S = np.eye(x_dim*2)\n",
        "\n",
        "    ### create env weights\n",
        "    w_x_y = np.random.normal(size=(2, x_dim, 1))/np.sqrt(x_dim)\n",
        "    c_e = [0. for i in range(len(e_tr)//2)] + [1. for i in range(len(e_tr)//2)]\n",
        "    random.shuffle(c_e)\n",
        "    index=0\n",
        "    for e in e_tr:\n",
        "        \n",
        "        w_x_y_e = w_x_y.copy()\n",
        "\n",
        "        if heteroskedastic:\n",
        "            sigma_y = 1\n",
        "            sigma_2 = e\n",
        "        else:\n",
        "            sigma_y = e\n",
        "            sigma_2 = 1\n",
        "        \n",
        "        b = c_e[index]\n",
        "        index+=1\n",
        "        w_x_y_e[1] = w_x_y_e[1]*b\n",
        "        \n",
        "        ## irm generative model\n",
        "        # h_e = np.random.normal(scale=e, size=(1000, x_dim))\n",
        "        # z_1 = np.random.normal(scale=e, size=(1000, x_dim)) + h_e @ w_h_x[0]\n",
        "        # #a =  h_e @ w_h_y\n",
        "        # #print(z_1.shape)\n",
        "        # y = z_1 @ w_x_y[0] + np.random.normal(scale=sigma_y, size=(1000, 1))+ h_e @ w_h_y\n",
        "        # #print((w_x_y[1]*y.reshape(-1)).shape)\n",
        "        # z_2 = (w_x_y[1]*y.reshape(-1)).T + np.random.normal(scale=sigma_2, size=(1000, x_dim)) + h_e @ w_h_x[1]\n",
        "\n",
        "        ### p-irm generative model\n",
        "        h_e = np.random.normal(scale=e, size=(1000, x_dim))\n",
        "        z_1 = np.random.normal(scale=e, size=(1000, x_dim)) + h_e @ w_h_x[0]\n",
        "        z_2 = np.random.normal(scale=e, size=(1000, x_dim)) + h_e @ w_h_x[1]\n",
        "        #a =  h_e @ w_h_y\n",
        "        #print(z_1.shape)\n",
        "        y = z_1 @ w_x_y_e[0] + z_2 @ w_x_y_e[1] + np.random.normal(scale=sigma_y, size=(1000, 1))+ h_e @ w_h_y\n",
        "        #print((w_x_y[1]*y.reshape(-1)).shape)\n",
        "        #z_2 = (w_x_y[1]*y.reshape(-1)).T + np.random.normal(scale=sigma_2, size=(1000, x_dim)) + h_e @ w_h_x[1]\n",
        "\n",
        "        Z_concat = np.concatenate((z_1, z_2), axis=1).T\n",
        "        #print(Z_concat.shape)\n",
        "\n",
        "        X = S.dot(Z_concat).T\n",
        "        print(X.shape)\n",
        "        list_envs.append((X, y, S, w_x_y_e, w_h_x))\n",
        "\n",
        "    return list_envs"
      ],
      "metadata": {
        "id": "C4RjnIIMRXx6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### model/training code\n",
        "\n",
        "class linear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim=20, output_dim=1):\n",
        "\n",
        "        super(linear, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Linear(input_dim, output_dim, bias=True))\n",
        "\n",
        "        #if(phi_dim > 1):\n",
        "        #    layers.append(nn.Linear(phi_dim, output_dim)) \n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      return self.net(x)\n",
        "\n",
        "\n",
        "def penalty(out, y, criterion, device):\n",
        "    scale = torch.tensor(1.).to(device).requires_grad_()\n",
        "    loss = criterion(out * scale, y)\n",
        "    grad = autograd.grad(loss, [scale], create_graph=True)[0]\n",
        "    return torch.sum(grad**2)\n",
        "\n",
        "\n",
        "def train_model(envs, model, optim, args):\n",
        "\n",
        "    p_weight = args.penalty_weight\n",
        "    penalty_anneal_epoch = args.penalty_anneal_epoch\n",
        "    method = args.method\n",
        "    criterion = args.loss_fxn\n",
        "    pen_criterion = args.pen_criterion\n",
        "    epochs = args.epochs\n",
        "    print_step = args.print_step\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    optimizer = optim    \n",
        "    d_num = len(envs)\n",
        "    \n",
        "    train_loss_ls = []\n",
        "    min_loss = 1e2 \n",
        "\n",
        "    print(\"number of envs: \", d_num)\n",
        "    max_val = 0\n",
        "    \n",
        "    \n",
        "    model.train()\n",
        "    model.to(torch.float)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        #val_acc_ls_epoch = []\n",
        "        #train_acc_ls_epoch = []\n",
        "        train_loss_ls_epoch = []\n",
        "\n",
        "        if(epoch == 0):\n",
        "            print(\"Training Model\")    \n",
        "            print(\"Method: \", args.method)\n",
        "\n",
        "        #print(\"Epoch: \", epoch)    \n",
        "        num_samples = 0\n",
        "        for i in range(d_num):\n",
        "\n",
        "            train_input = torch.from_numpy(envs[i][\"data\"]).to(device).to(torch.float)\n",
        "            train_label = torch.from_numpy(envs[i][\"label\"]).to(device).to(torch.float)\n",
        "            \n",
        "            output = model(train_input)\n",
        "\n",
        "            ### reduction = sum\n",
        "            num_samples += train_input.size(0) \n",
        "            envs[i]['loss'] = criterion(output, train_label)\n",
        "            #envs[i]['acc'] = mean_accuracy(logits, train_label)\n",
        "            envs[i]['penalty'] = penalty(output, train_label, pen_criterion, device)\n",
        "\n",
        "        train_loss = (torch.stack([envs[i]['loss'] for i in range(d_num)]).sum())/num_samples\n",
        "        train_loss_ls.append(train_loss.item())\n",
        "\n",
        "        if method == 'irm':\n",
        "            \n",
        "            train_penalty = torch.stack([envs[i]['penalty'] for i in range(d_num) if (envs[i]['penalty_condition'] == True)]).mean()\n",
        "            penalty_weight = (p_weight if epoch >= penalty_anneal_epoch else 0.)\n",
        "            train_loss += penalty_weight * train_penalty\n",
        "            if penalty_weight > 1.0:\n",
        "                train_loss /= penalty_weight\n",
        "        elif method == 'erm':\n",
        "            penalty_weight = 0.\n",
        "\n",
        "            ### set penalty to 0\n",
        "            train_penalty = envs[d_num[0]]['penalty'] * 0.  # so that this term is a tensor\n",
        "        else:\n",
        "            raise NotImplementedError    \n",
        "\n",
        "        model.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()      \n",
        "\n",
        "        if (epoch+1) % (print_step) == 0 or (epoch+1) == penalty_anneal_epoch:\n",
        "            print(f'Epoch: {epoch+1} | Training Loss: {train_loss_ls[epoch]:.3f}')\n",
        "            print(train_penalty)\n",
        "            feat_vec = model.net[0].weight.detach().clone().to(\"cpu\").numpy().T\n",
        "            print(\"norm_feat_1:\", np.linalg.norm(feat_vec[:10]))\n",
        "            print(\"norm_feat_2:\", np.linalg.norm(feat_vec[10:]))\n",
        "\n",
        "    return train_loss_ls[-1], model.net[0].weight.detach().clone().to(\"cpu\").numpy().T"
      ],
      "metadata": {
        "id": "5JmHWY-Bc_s1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_performance(train_envs, opt, seeds=3, method = 'irm'):\n",
        "\n",
        "    opt.method = method\n",
        "    train_losses = []\n",
        "    feat_vectors = []\n",
        "\n",
        "    for i in range(seeds):\n",
        "\n",
        "        #torch.random.manual_seed(i)\n",
        "        \n",
        "        #my_model = feedforward(num_hiddenlayers=opt.hidden_layers, hidden_width=opt.hidden_width)\n",
        "        my_model = linear(input_dim=opt.x_dim*2)\n",
        "        optimizer = torch.optim.Adam(my_model.parameters(), lr=1e-2)\n",
        "        train_loss, feature_vector = train_model(train_envs, my_model, optimizer, opt)\n",
        "\n",
        "        feat_vectors.append(feature_vector)\n",
        "\n",
        "    return train_losses, feat_vectors"
      ],
      "metadata": {
        "id": "XkCWWZRlu313"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(230)\n",
        "#torch.manual_seed(230)\n",
        "\n",
        "my_list = create_generative_model({0.2, 1, 2, 5})\n",
        "\n",
        "my_train_envs = []\n",
        "for i in my_list:\n",
        "  my_dict = {}\n",
        "  my_dict[\"data\"] = i[0]\n",
        "  my_dict[\"label\"] = i[1]\n",
        "  my_dict[\"S\"] = i[2]\n",
        "  my_dict[\"true_wts\"] = i[3]\n",
        "  my_dict[\"penalty_condition\"] = True\n",
        "\n",
        "  my_train_envs.append(my_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnIkUTGTkuDh",
        "outputId": "c41f1608-42bf-4c4c-a6e9-1037f697bf00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in my_train_envs:\n",
        "  wts = i[\"true_wts\"]\n",
        "  print(\"norm_feat_1:\", np.linalg.norm(wts[0]))\n",
        "  print(\"norm_feat_2:\", np.linalg.norm(wts[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilRi_HT278ir",
        "outputId": "0ef85c56-3597-4ed7-8a8a-7bd1bd1e9316"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm_feat_1: 1.0190515812794492\n",
            "norm_feat_2: 1.232877303258899\n",
            "norm_feat_1: 1.0190515812794492\n",
            "norm_feat_2: 0.0\n",
            "norm_feat_1: 1.0190515812794492\n",
            "norm_feat_2: 1.232877303258899\n",
            "norm_feat_1: 1.0190515812794492\n",
            "norm_feat_2: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Namespace()\n",
        "opt.penalty_weight = 1e3\n",
        "opt.x_dim = 10\n",
        "#opt.penalty_anneal_epoch = 1000'\n",
        "#opt.method = 'irm'\n",
        "opt.loss_fxn = torch.nn.MSELoss(reduction='sum')\n",
        "opt.epochs = 40000\n",
        "opt.pen_criterion = torch.nn.MSELoss(reduction='mean')\n",
        "opt.print_step = 40000\n",
        "opt.penalty_anneal_epoch = 4000"
      ],
      "metadata": {
        "id": "c1IDmeFFw2qO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.random.seed(230)\n",
        "#torch.manual_seed(230)\n",
        "\n",
        "act_norm = []\n",
        "learned_norm = []\n",
        "\n",
        "for seed in range(5):\n",
        "  \n",
        "  my_list = create_generative_model({0.2, 1, 2, 5})\n",
        "  my_train_envs = []\n",
        "  ct=0\n",
        "  for i in my_list:\n",
        "      my_dict = {}\n",
        "      my_dict[\"data\"] = i[0]\n",
        "      my_dict[\"label\"] = i[1]\n",
        "      my_dict[\"S\"] = i[2]\n",
        "      my_dict[\"true_wts\"] = i[3]\n",
        "      my_dict[\"penalty_condition\"] = True\n",
        "\n",
        "      my_train_envs.append(my_dict)\n",
        "  \n",
        "  for i in my_train_envs:\n",
        "      wts = i[\"true_wts\"]\n",
        "      # print(\"norm_feat_1:\", np.linalg.norm(wts[0]))\n",
        "      # print(\"norm_feat_2:\", np.linalg.norm(wts[1]))\n",
        "\n",
        "  for j in my_train_envs:\n",
        "    wts = j[\"true_wts\"]\n",
        "    feat_1_norm = np.linalg.norm(wts[0])\n",
        "    feat_2_norm = np.linalg.norm(wts[1])\n",
        "\n",
        "    if(feat_2_norm>0 and ct==0):\n",
        "      act_norm.append((feat_1_norm, feat_2_norm))\n",
        "      ct += 1\n",
        "  \n",
        "  # else:\n",
        "  a, b = get_performance(my_train_envs, opt, seeds=1, method='irm')\n",
        "  learned_norm.append((np.linalg.norm(b[0][:10]), np.linalg.norm(b[0][10:])))\n",
        "\n",
        "  print(\"ratio 1:\", learned_norm[-1][0]/act_norm[-1][0])\n",
        "  print(\"ratio 2:\", learned_norm[-1][1]/act_norm[-1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njEKgUfP0UPH",
        "outputId": "19853636-c093-4261-cd36-eb5b1776d215"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "number of envs:  4\n",
            "Training Model\n",
            "Method:  irm\n",
            "Epoch: 4000 | Training Loss: 8.137\n",
            "tensor(19.3856, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 1.0879968\n",
            "norm_feat_2: 0.7862485\n",
            "Epoch: 40000 | Training Loss: 13.090\n",
            "tensor(3.0260e-06, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 1.0301751\n",
            "norm_feat_2: 0.22118486\n",
            "ratio 1: 0.9463308961048553\n",
            "ratio 2: 0.22749294367821862\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "number of envs:  4\n",
            "Training Model\n",
            "Method:  irm\n",
            "Epoch: 4000 | Training Loss: 8.023\n",
            "tensor(24.6172, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 1.0093901\n",
            "norm_feat_2: 1.0148733\n",
            "Epoch: 40000 | Training Loss: 16.788\n",
            "tensor(5.9927e-05, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 0.97612756\n",
            "norm_feat_2: 0.24542104\n",
            "ratio 1: 0.9671293103021358\n",
            "ratio 2: 0.22073402585632415\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "number of envs:  4\n",
            "Training Model\n",
            "Method:  irm\n",
            "Epoch: 4000 | Training Loss: 7.397\n",
            "tensor(0.0008, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 0.5735995\n",
            "norm_feat_2: 0.06495551\n",
            "Epoch: 40000 | Training Loss: 7.412\n",
            "tensor(4.1909e-08, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 0.5775914\n",
            "norm_feat_2: 0.046560112\n",
            "ratio 1: 0.9390192803035587\n",
            "ratio 2: 0.052671003252861795\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "number of envs:  4\n",
            "Training Model\n",
            "Method:  irm\n",
            "Epoch: 4000 | Training Loss: 8.082\n",
            "tensor(0.0028, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 0.5757536\n",
            "norm_feat_2: 0.057374235\n",
            "Epoch: 40000 | Training Loss: 8.110\n",
            "tensor(0.0006, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 0.5718098\n",
            "norm_feat_2: 0.059194893\n",
            "ratio 1: 0.9944723737038194\n",
            "ratio 2: 0.07866205068343515\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "(1000, 20)\n",
            "number of envs:  4\n",
            "Training Model\n",
            "Method:  irm\n",
            "Epoch: 4000 | Training Loss: 7.987\n",
            "tensor(0.0105, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 1.4221737\n",
            "norm_feat_2: 0.09342203\n",
            "Epoch: 40000 | Training Loss: 8.116\n",
            "tensor(0.0035, grad_fn=<MeanBackward0>)\n",
            "norm_feat_1: 1.4224899\n",
            "norm_feat_2: 0.0941463\n",
            "ratio 1: 1.0187684636346943\n",
            "ratio 2: 0.10986166868797573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratios_1 = []\n",
        "ratios_2 = []\n",
        "for seed in range(5):\n",
        "    ratios_1.append(learned_norm[seed][0]/act_norm[seed][0])\n",
        "    ratios_2.append(learned_norm[seed][1]/act_norm[seed][1])"
      ],
      "metadata": {
        "id": "-0rJyg3l4ERK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "materials = ['feature_1 (invariant)', 'feature_2 (non-invariant)']\n",
        "x_pos = np.arange(len(materials))\n",
        "CTEs = [np.mean(ratios_1), np.mean(ratios_2)]\n",
        "error = [np.std(ratios_1), np.std(ratios_2)]"
      ],
      "metadata": {
        "id": "5huqZg-e5cE1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# creating the bar plot\n",
        "fig, ax = plt.subplots(figsize = (4.5, 4.5))\n",
        "ax.bar(x_pos, CTEs, yerr=error, align='center', alpha=0.5, ecolor='black', capsize=10, width=0.4)\n",
        "ax.set_ylabel('Ratio of Feature Weight Norm (Learnt over Actual)')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(materials)\n",
        "ax.set_title('Demonstration of IRM supressing non-invariant features')\n",
        "ax.yaxis.grid(True)\n",
        "\n",
        "# Save the figure and show\n",
        "plt.tight_layout()\n",
        "#plt.savefig('bar_plot_with_error_bars.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "S0Ri-3Jr4x9T",
        "outputId": "58e7c656-57d7-4e10-a060-d19faac48347"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 324x324 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}